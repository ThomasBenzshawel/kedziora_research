{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bdb\n",
    "import importlib\n",
    "import os\n",
    "import pdb\n",
    "import shutil\n",
    "import sys\n",
    "import tempfile\n",
    "import traceback\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "os.chdir('C:\\Repos\\kedziora_research\\kedziora_research')\n",
    "from summer_dev.train_test.test import OverfitLoggerNull\n",
    "from typing import List, Optional\n",
    "import random\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import lightning as L\n",
    "import torch\n",
    "import yaml\n",
    "from loguru import logger as loguru_logger\n",
    "from omegaconf import OmegaConf\n",
    "from packaging import version\n",
    "from pycg import exp\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from lightning.pytorch.strategies import DDPStrategy\n",
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "from pytorch_lightning.utilities.exceptions import MisconfigurationException\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "from summer_dev.utils import wandb_util\n",
    "\n",
    "if version.parse(pl.__version__) > version.parse('1.8.0'):\n",
    "    from pytorch_lightning.callbacks import Callback\n",
    "else:\n",
    "    from pytorch_lightning.callbacks.base import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CopyModelFileCallback(Callback):\n",
    "    def __init__(self):\n",
    "        self.source_path = None\n",
    "        self.target_path = None\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        if self.source_path is not None and self.target_path is not None:\n",
    "            if self.target_path.parent.exists():\n",
    "                shutil.move(self.source_path, self.target_path)\n",
    "\n",
    "\n",
    "class CustomizedDataParallel(DataParallel):\n",
    "    def scatter(self, inputs, kwargs, device_ids):\n",
    "        inputs = self.module.module.dp_scatter(inputs, device_ids, self.dim) if inputs else []\n",
    "        kwargs = self.module.module.dp_scatter(kwargs, device_ids, self.dim) if kwargs else []\n",
    "        if len(inputs) < len(kwargs):\n",
    "            inputs.extend([() for _ in range(len(kwargs) - len(inputs))])\n",
    "        elif len(kwargs) < len(inputs):\n",
    "            kwargs.extend([{} for _ in range(len(inputs) - len(kwargs))])\n",
    "        inputs = tuple(inputs)\n",
    "        kwargs = tuple(kwargs)\n",
    "        return inputs, kwargs\n",
    "\n",
    "\n",
    "# class CustomizedDataParallelStrategy(DDPStrategy):\n",
    "#     def __init__(self, parallel_devices: Optional[List[torch.device]]):\n",
    "#         # Parallel devices will be later populated in accelerator. Well done!\n",
    "#         super().__init__(parallel_devices=parallel_devices)\n",
    "\n",
    "#     def setup(self, model):\n",
    "#         from pytorch_lightning.overrides.data_parallel import \\\n",
    "#             LightningParallelModule\n",
    "\n",
    "#         # model needs to be moved to the device before it is wrapped\n",
    "#         model.to(self.root_device)\n",
    "#         self._model = CustomizedDataParallel(LightningParallelModule(model), self.parallel_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_usable_gpus():\n",
    "    if program_args.gpus is None:\n",
    "        program_args.gpus = 1\n",
    "\n",
    "    if \"CUDA_VISIBLE_DEVICES\" in os.environ.keys():\n",
    "        original_cvd = [int(t) for t in os.environ['CUDA_VISIBLE_DEVICES'].split(',')]\n",
    "    else:\n",
    "        original_cvd = []\n",
    "\n",
    "    if len(original_cvd) == program_args.gpus:\n",
    "        # Everything is fine.\n",
    "        return\n",
    "\n",
    "    # Mismatched/missing CVD setting & #gpus, reset.\n",
    "    gpu_states = exp.get_gpu_status(\"localhost\")\n",
    "    # temporally remove this to run multiple experiments on the same machine\n",
    "    available_gpus = [t for t in gpu_states if t.gpu_mem_usage < 0.2 and t.gpu_compute_usage < 0.2]\n",
    "    # available_gpus = [t for t in gpu_states]\n",
    "\n",
    "    if len(available_gpus) == 0:\n",
    "        print(\"You cannot use GPU. Everything is full.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    if len(available_gpus) < program_args.gpus:\n",
    "        print(f\"Warning: Available GPUs are {[t.gpu_id for t in available_gpus]}, \"\n",
    "              f\"but you want to use {program_args.gpus} GPUs.\")\n",
    "        program_args.gpus = len(available_gpus)\n",
    "\n",
    "    available_gpus = available_gpus[:program_args.gpus]\n",
    "    selection_str = ','.join([str(t.gpu_id) for t in available_gpus])\n",
    "    print(f\"Intelligent GPU selection: {selection_str}\")\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = selection_str\n",
    "\n",
    "def is_rank_zero():\n",
    "    # It will also set LOCAL_RANK env variable, so using that will be more consistent.\n",
    "    return os.environ.get('MASTER_PORT', None) is None\n",
    "\n",
    "def is_rank_node_zero():\n",
    "    return os.environ.get('NODE_RANK', '0') == '0'\n",
    "\n",
    "def remove_option(parser, option):\n",
    "    for action in parser._actions:\n",
    "        if vars(action)['option_strings'][0] == option:\n",
    "            parser._handle_conflict_resolve(None, [(option, action)])\n",
    "            break\n",
    "\n",
    "\n",
    "def readable_name_from_exec(exec_list: List[str]):\n",
    "    keys = {}\n",
    "    for exec_str in exec_list:\n",
    "        kvs = exec_str.split(\"=\")\n",
    "        k_name = kvs[0]\n",
    "        k_name_arr = [\"\".join([us[0] for us in t.split(\"_\") if len(us) > 0]) for t in k_name.split(\".\")]\n",
    "        # Collapse leading dots except for the last one.\n",
    "        k_name = ''.join(k_name_arr[:-2]) + '.'.join(k_name_arr[-2:])\n",
    "        k_value = kvs[1]\n",
    "        if k_value.lower() in [\"true\", \"false\"]:\n",
    "            k_value = str(int(k_value.lower() == \"true\"))\n",
    "        keys[k_name] = k_value\n",
    "    return '-'.join([k + keys[k] for k in sorted(list(keys.keys()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.cli import LightningCLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Trainer' has no attribute 'add_argparse_args'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m\n\u001b[0;32m     20\u001b[0m program_parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--seed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSet a random seed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# add pl args\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m program_parser \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_argparse_args\u001b[49m(program_parser)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Remove some args, which we think should be model-based.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m remove_option(program_parser, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--accumulate_grad_batches\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Trainer' has no attribute 'add_argparse_args'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "[1] Parse and initialize program arguments\n",
    "    these include: --debug, --profile, --gpus, --num_nodes, --resume, ...\n",
    "    they will NOT be saved for a checkpoints.\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "def cli_new_main():\n",
    "    program_parser = exp.argparse.ArgumentParser()\n",
    "    program_parser.add_argument('--debug', action='store_true', help='Use debug mode of pytorch')\n",
    "    program_parser.add_argument('--resume', action='store_true', help='Continue training. Use hparams.yaml file.')\n",
    "    program_parser.add_argument('--nolog', action='store_true', help='Do not create any logs.')\n",
    "    program_parser.add_argument('--nosync', action='store_true', help='Do not synchronize nas even if forced.')\n",
    "    program_parser.add_argument('--save_topk', default=2, type=int, help='How many top models to save. -1 to save all models.')\n",
    "    program_parser.add_argument('--validate_first', action='store_true', help='Do a full validation with logging before training starts.')\n",
    "    program_parser.add_argument('--logger_type', choices=['tb', 'wandb', 'none'], default='wandb')\n",
    "    program_parser.add_argument('--wname', default=None, type=str, help='Run name to be appended to wandb')\n",
    "    program_parser.add_argument('--wandb_base', type=str, default=\"../wandb/\", help=\"Path to wandb base directory.\")\n",
    "    program_parser.add_argument('--eval_interval', type=int, default=1, help='How often to evaluate the model.')\n",
    "    program_parser.add_argument('--save_every', default=50, type=int, help='How often to save the model.')\n",
    "    program_parser.add_argument('--resume_from_ckpt', default=None, type=str, help='checkpoint path we want to load')\n",
    "    program_parser.add_argument('--model_precision', default=32, help='Model precision to use.')\n",
    "    program_parser.add_argument('--seed', type=int, default=0, help='Set a random seed.')\n",
    "\n",
    "\n",
    "\n",
    "# add pl args\n",
    "program_parser = pl.Trainer.add_argparse_args(program_parser)\n",
    "# Remove some args, which we think should be model-based.\n",
    "remove_option(program_parser, '--accumulate_grad_batches')\n",
    "program_args, other_args = program_parser.parse_known_args()\n",
    "\n",
    "loguru_logger.info(f\"This is train_auto.py! Please note that you should use 300 instead of 300.0 for resuming.\")\n",
    "\n",
    "model_parser = exp.ArgumentParserX(base_config_path='configs/default/param.yaml')\n",
    "model_args = model_parser.parse_args(other_args)\n",
    "hyper_path = model_args.hyper\n",
    "del model_args[\"hyper\"]\n",
    "\n",
    "# Default logger type\n",
    "if program_args.nolog:\n",
    "    program_args.logger_type = 'none'\n",
    "\n",
    "# AUTO resume with wandb logger\n",
    "## uncomment if you want to use it and fill in your own <WANDB_USER_NAME>!\n",
    "# if program_args.logger_type == 'wandb':\n",
    "#     wname = program_args.wname\n",
    "#     sep_pos = str(model_args.name).find('/')\n",
    "#     project_name = model_args.name[:sep_pos]\n",
    "#     run_name = model_args.name[sep_pos + 1:] + \"/\" + wname\n",
    "\n",
    "#     check_wandb_name = \"<WANDB_USER_NAME>/xcube-%s/%s:last\" % (project_name, run_name)\n",
    "#     try:\n",
    "#         print(\"Try to load from wandb:\", check_wandb_name)\n",
    "#         wdb_run, args_ckpt = wandb_util.get_wandb_run(check_wandb_name, wdb_base=program_args.wandb_base, default_ckpt=\"last\")\n",
    "#         assert args_ckpt is not None, \"Please specify checkpoint version!\"\n",
    "#         assert args_ckpt.exists(), \"Selected checkpoint does not exist!\"\n",
    "#         print(\"Load from wandb:\", check_wandb_name)\n",
    "#         program_args.resume = True\n",
    "#         other_args[0] = check_wandb_name\n",
    "#     except:\n",
    "#         print(\"No wandb checkpoint found, start training from scratch\")\n",
    "#         pass\n",
    "\n",
    "# Force not to sync to shorten bootstrap time.\n",
    "if program_args.nosync:\n",
    "    os.environ['NO_SYNC'] = '1'\n",
    "\n",
    "# Train forever\n",
    "if program_args.max_epochs is None:\n",
    "    program_args.max_epochs = -1\n",
    "\n",
    "\n",
    "\n",
    "# Going to be different in the future TODO\n",
    "if is_rank_zero():\n",
    "    # Detect usable GPUs.\n",
    "    determine_usable_gpus()\n",
    "    # Wandb version check\n",
    "    if program_args.gpus > 1 and program_args.accelerator is None:\n",
    "        if version.parse(pl.__version__) > version.parse('1.8.0'):\n",
    "            program_args.strategy = 'ddp'\n",
    "            program_args.accelerator = \"gpu\"\n",
    "        else:\n",
    "            program_args.accelerator = 'ddp'\n",
    "\n",
    "    if version.parse(pl.__version__) > version.parse('1.5.0'):\n",
    "        program_args.devices = program_args.gpus\n",
    "        del program_args.gpus\n",
    "        program_args.accelerator = \"gpu\"\n",
    "else:\n",
    "    # Align parameters.\n",
    "    if version.parse(pl.__version__) > version.parse('1.8.0'):\n",
    "        program_args.strategy = 'ddp'\n",
    "        program_args.accelerator = \"gpu\"\n",
    "        program_args.devices = program_args.gpus\n",
    "        del program_args.gpus\n",
    "    else:\n",
    "        program_args.accelerator = 'ddp'\n",
    "        \n",
    "################################################\n",
    "\n",
    "\n",
    "# Profiling and debugging options\n",
    "torch.autograd.set_detect_anomaly(program_args.debug)\n",
    "\n",
    "# specify logdir if not use wandb\n",
    "dirpath = None\n",
    "if program_args.logger_type == 'none':\n",
    "    wname = os.path.basename(hyper_path).split(\".\")[0]\n",
    "    sep_pos = str(model_args.name).find('/')\n",
    "    project_name = model_args.name[:sep_pos]\n",
    "    run_name = model_args.name[sep_pos + 1:] + \"_\" + wname\n",
    "    logdir = os.path.join(\"./checkpoints\", project_name, run_name)\n",
    "    os.makedirs(logdir, exist_ok=True)\n",
    "    dirpath = logdir\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=dirpath,\n",
    "    filename='{epoch:06d}-{step:09d}',\n",
    "    save_last=True,\n",
    "    save_top_k=program_args.save_topk,\n",
    "    monitor=\"val_step\",\n",
    "    mode=\"max\",\n",
    "    every_n_train_steps=program_args.save_every,\n",
    ")\n",
    "lr_record_callback = LearningRateMonitor(logging_interval='step')\n",
    "copy_model_file_callback = CopyModelFileCallback()\n",
    "\n",
    "# Determine parallel plugin:\n",
    "if program_args.accelerator == 'ddp':\n",
    "    if version.parse(pl.__version__) < version.parse('1.8.0'):\n",
    "        from pytorch_lightning.plugins import DDPPlugin\n",
    "        accelerator_plugins = [DDPPlugin(find_unused_parameters=False)]\n",
    "    else:\n",
    "        accelerator_plugins = []\n",
    "elif program_args.accelerator == 'dp':\n",
    "    accelerator_plugins = [CustomizedDataParallelPlugin(None)]\n",
    "else:\n",
    "    accelerator_plugins = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "[2] Determine model arguments\n",
    "    MODEL args include: --lr, --num_layers, etc. (everything defined in YAML)\n",
    "    These use AP-X module, which accepts CLI and YAML inputs.\n",
    "    These args will be saved as hyper-params.\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "if program_args.resume:\n",
    "    raw_hyper = other_args[0]\n",
    "    if raw_hyper.startswith(\"wdb:\"):\n",
    "        # Load config and replace\n",
    "        wdb_run, wdb_ckpt = wandb_util.get_wandb_run(raw_hyper, program_args.wandb_base, default_ckpt=\"last\")\n",
    "        tmp_yaml_name = '/tmp/' + str(uuid.uuid4()) + '.yaml'\n",
    "        with open(tmp_yaml_name, 'w') as outfile:\n",
    "            yaml.dump(wandb_util.recover_from_wandb_config(wdb_run.config), outfile)\n",
    "        other_args[0] = tmp_yaml_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "[3] Build / restore logger and checkpoints.\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "# Set checkpoint auto-save options.\n",
    "last_ckpt_path = None\n",
    "if program_args.resume_from_ckpt is not None:\n",
    "    last_ckpt_path = program_args.resume_from_ckpt\n",
    "\n",
    "if program_args.logger_type == 'tb':\n",
    "    if not program_args.resume:\n",
    "        logger_version_num = None\n",
    "        last_ckpt_path = None\n",
    "    else:\n",
    "        last_ckpt_path = Path(hyper_path).parent / \"checkpoints\" / \"last.ckpt\"\n",
    "        logger_version_num = Path(hyper_path).parent.name if program_args.resume else None\n",
    "    logger = TensorBoardLogger('../checkpoints/', name=model_args.name,\n",
    "                                version=logger_version_num, default_hp_metric=False)\n",
    "    # Call this property to assign the version early, so we don't have to wait for the model to be loaded\n",
    "    print(f\"Tensorboard logger, version number =\", logger.version)\n",
    "elif program_args.logger_type == 'wandb':\n",
    "    # Will create wandb folder automatically\n",
    "    from datetime import datetime, timedelta\n",
    "    import randomname\n",
    "\n",
    "    if not program_args.resume:\n",
    "        wname = program_args.wname\n",
    "        if 'WANDB_SWEEP_ID' in os.environ.keys():\n",
    "            # (Use exec to determine good names)\n",
    "            wname = os.environ['WANDB_SWEEP_ID'] + \"-\" + readable_name_from_exec(model_args.exec)\n",
    "        if wname is None:\n",
    "            # Example: 0105-clever-monkey\n",
    "            wname = (datetime.utcnow() + timedelta(hours=8)).strftime('%m%d') + \"-\" + randomname.get_name()\n",
    "        sep_pos = str(model_args.name).find('/')\n",
    "        if sep_pos == -1:\n",
    "            project_name = model_args.name\n",
    "            run_name = \"root/\" + wname\n",
    "        else:\n",
    "            project_name = model_args.name[:sep_pos]\n",
    "            run_name = model_args.name[sep_pos + 1:] + \"/\" + wname\n",
    "\n",
    "        if is_rank_node_zero():\n",
    "            logger = WandbLogger(name=run_name, save_dir=program_args.wandb_base, project='xcube-' + project_name)\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        if is_rank_node_zero():\n",
    "            logger = WandbLogger(name=wdb_run.name, save_dir=program_args.wandb_base, project=wdb_run.project, id=wdb_run.id)\n",
    "        else:\n",
    "            pass\n",
    "        last_ckpt_path = wdb_ckpt\n",
    "        os.unlink(tmp_yaml_name)\n",
    "else:\n",
    "    logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "[4] Build trainer and determine final hparams. Set AMP if needed.\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "# Do it here because wandb name need some randomness.\n",
    "if program_args.seed == -1:\n",
    "    # random seed\n",
    "    program_args.seed = random.randint(0, 1000000)\n",
    "\n",
    "pl.seed_everything(program_args.seed)\n",
    "\n",
    "# Build trainer\n",
    "trainer = pl.Trainer.from_argparse_args(\n",
    "    program_args,\n",
    "    callbacks=[checkpoint_callback, lr_record_callback, copy_model_file_callback]\n",
    "    if logger is not None else [checkpoint_callback],\n",
    "    logger=logger,\n",
    "    log_every_n_steps=20,\n",
    "    check_val_every_n_epoch=program_args.eval_interval,\n",
    "    plugins=accelerator_plugins,\n",
    "    accumulate_grad_batches=model_args.accumulate_grad_batches,\n",
    "    precision=program_args.model_precision)\n",
    "# fix wandb global_step resume bug\n",
    "if program_args.resume:\n",
    "    # get global step offset\n",
    "    checkpoint = torch.load(last_ckpt_path, map_location='cpu')\n",
    "    global_step_offset = checkpoint[\"global_step\"]\n",
    "    trainer.fit_loop.epoch_loop._batches_that_stepped = global_step_offset\n",
    "    del checkpoint    \n",
    "\n",
    "net_module = importlib.import_module(\"models.\" + model_args.model).Model\n",
    "net_model = net_module(model_args)\n",
    "\n",
    "@rank_zero_only\n",
    "def print_model_summary():\n",
    "    print(\" >>>> ======= MODEL HYPER-PARAMETERS ======= <<<< \")\n",
    "    print(OmegaConf.to_yaml(net_model.hparams, resolve=True))\n",
    "    print(\" >>>> ====================================== <<<< \")\n",
    "\n",
    "print_model_summary()\n",
    "\n",
    "# No longer use this..\n",
    "del is_rank_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "[5] Main training iteration.\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "# Note: In debug mode, trainer.fit will automatically end if NaN occurs in backward.\n",
    "e = None\n",
    "try:\n",
    "    net_model.overfit_logger = OverfitLoggerNull()\n",
    "    if program_args.validate_first:\n",
    "        trainer.validate(net_model, ckpt_path=last_ckpt_path)\n",
    "    with exp.pt_profile_named(\"training\", \"1.json\"):\n",
    "        trainer.fit(net_model, ckpt_path=last_ckpt_path)\n",
    "except Exception as ex:\n",
    "    e = ex\n",
    "    # https://stackoverflow.com/questions/52081929/pdb-go-to-a-frame-in-exception-within-exception\n",
    "    if isinstance(e, MisconfigurationException):\n",
    "        if e.__context__ is not None:\n",
    "            traceback.print_exc()\n",
    "            if program_args.accelerator is None:\n",
    "                pdb.post_mortem(e.__context__.__traceback__)\n",
    "    elif isinstance(e, bdb.BdbQuit):\n",
    "        print(\"Post mortem is skipped because the exception is from Pdb.\")\n",
    "    else:\n",
    "        traceback.print_exc()\n",
    "        if program_args.accelerator is None:\n",
    "            pdb.post_mortem(e.__traceback__)\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "[6] If ended premature, add to delete list.\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "if trainer.current_epoch < 1 and last_ckpt_path is None and trainer.local_rank == 0:\n",
    "    if program_args.logger_type == 'tb':\n",
    "        if Path(trainer.log_dir).exists():\n",
    "            with open(\".premature_checkpoints\", \"a\") as f:\n",
    "                f.write(f\"{trainer.log_dir}\\n\")\n",
    "            print(f\"\\n\\nTB Checkpoint at {trainer.log_dir} marked to be cleared.\\n\\n\")\n",
    "        sys.exit(-1)\n",
    "    elif program_args.logger_type == 'wandb':\n",
    "        with open(\".premature_checkpoints\", \"a\") as f:\n",
    "            f.write(f\"wdb:{trainer.logger.experiment.path}:{trainer.logger.experiment.name}\\n\")\n",
    "        print(f\"\\n\\nWandb Run of {trainer.logger.experiment.path} \"\n",
    "                f\"(with name {trainer.logger.experiment.name}) marked to be cleared.\\n\\n\")\n",
    "        sys.exit(-1)\n",
    "\n",
    "if trainer.local_rank == 0:\n",
    "    print(f\"Training Finished. Best path = {checkpoint_callback.best_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
