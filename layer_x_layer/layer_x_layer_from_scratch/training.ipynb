{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9ca53d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Mapping, Optional, Union\n",
    "import collections\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "# For CLIP embeddings\n",
    "import clip\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ab704",
   "metadata": {},
   "source": [
    "# Todo\n",
    "Layer by layer embedder that feeds into 2 layers in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43c9b6b",
   "metadata": {},
   "source": [
    "# Diffusion Model\n",
    "A model that generates layers of a voxelized 3D model one layer at a time through defusion.\n",
    "\n",
    "The general idea of this is to do diffusion twice.\n",
    "\n",
    "The first diffusion is done for each layer. Each layer goes through all diffusion time steps, and is combined at the end to be a 3D object.\n",
    "\n",
    "This is done for x granularities of voxels, where each previous granularity informs the current granularity level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "178b8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, channels, num_heads=8, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = channels // num_heads\n",
    "        \n",
    "        num_groups = min(8, channels)\n",
    "        while channels % num_groups != 0:\n",
    "            num_groups -= 1\n",
    "        self.norm = nn.GroupNorm(num_groups, channels)\n",
    "\n",
    "        self.qkv = nn.Conv2d(channels, channels * 3, 1)  # 1x1 conv for Q, K, V\n",
    "        self.proj = nn.Conv2d(channels, channels, 1)\n",
    "\n",
    "        assert channels % num_heads == 0, f\"channels {channels} must be divisible by num_heads {num_heads}\"\n",
    "\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        \n",
    "        # Normalize\n",
    "        h = self.norm(x)\n",
    "        \n",
    "        # Get Q, K, V\n",
    "        qkv = self.qkv(h)\n",
    "        q, k, v = qkv.chunk(3, dim=1)\n",
    "        \n",
    "        # Reshape for multi-head attention\n",
    "        q = q.view(B, self.num_heads, self.head_dim, H * W).transpose(2, 3)  # [B, heads, HW, head_dim]\n",
    "        k = k.view(B, self.num_heads, self.head_dim, H * W).transpose(2, 3)\n",
    "        v = v.view(B, self.num_heads, self.head_dim, H * W).transpose(2, 3)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        scale = self.head_dim ** -0.5\n",
    "        attn = torch.matmul(q, k.transpose(-2, -1)) * scale\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        attn = self.attn_dropout(attn)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        out = torch.matmul(attn, v)  # [B, heads, HW, head_dim]\n",
    "        out = out.transpose(2, 3).contiguous().view(B, C, H, W)\n",
    "        \n",
    "        # Project and add residual\n",
    "        out = self.proj(out)\n",
    "        return x + out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9cea4016",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A more standard implementation where context is properly projected \n",
    "    and can attend to multiple positions\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, context_dim, num_heads=8, context_tokens=8):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.context_dim = context_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = channels // num_heads\n",
    "        self.context_tokens = context_tokens\n",
    "\n",
    "        self.norm = nn.GroupNorm(min(8, channels), channels)\n",
    "        self.q = nn.Conv2d(channels, channels, 1)\n",
    "\n",
    "        # Project context to key and value\n",
    "        self.context_mlp_proj = nn.Sequential(\n",
    "            nn.Linear(context_dim, context_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(context_dim * 2, channels * self.context_tokens * 2)\n",
    "        )\n",
    "        \n",
    "        # Final projection\n",
    "        self.proj = nn.Conv2d(channels, channels, 1)\n",
    "\n",
    "        self.context_pos_emb = nn.Parameter(\n",
    "            torch.randn(1, self.context_tokens, channels) * 0.02\n",
    "        )\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x, context):\n",
    "        B, C, H, W = x.shape\n",
    "        \n",
    "        # Normalize spatial features\n",
    "        h = self.norm(x)\n",
    "        \n",
    "        # Query from spatial features\n",
    "        q = self.q(h)  # [B, C, H, W]\n",
    "        q = q.view(B, self.num_heads, self.head_dim, H * W)\n",
    "        q = q.permute(0, 1, 3, 2)  # [B, heads, HW, head_dim]\n",
    "        \n",
    "        # Project context to key and value\n",
    "        context_proj = self.context_mlp_proj(context)  # [B, channels * context_tokens * 2]\n",
    "        context_proj = context_proj.view(B, self.context_tokens, 2, self.channels)\n",
    "\n",
    "        context_proj[:, :, 1] += self.context_pos_emb  # Add to V only  \n",
    "        k, v = context_proj[:, :, 0], context_proj[:, :, 1]  # Each is [B, context_tokens, channels]\n",
    "        \n",
    "        # Add sequence dimension to k and v\n",
    "        k = k.view(B, self.context_tokens, self.num_heads, self.head_dim)\n",
    "        v = v.view(B, self.context_tokens, self.num_heads, self.head_dim)\n",
    "        k = k.permute(0, 2, 1, 3)  # [B, heads, num_tokens, head_dim]\n",
    "        v = v.permute(0, 2, 1, 3)  # [B, heads, num_tokens, head_dim]\n",
    "\n",
    "        # Compute attention scores\n",
    "        scale = self.head_dim ** -0.5\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) * scale  # [B, heads, HW, 1]\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        # Apply attention \n",
    "        out = torch.matmul(attn, v)\n",
    "        \n",
    "        # Reshape back to spatial dimensions\n",
    "        out = out.permute(0, 1, 3, 2).contiguous()  # [B, heads, head_dim, HW]\n",
    "        out = out.view(B, C, H, W)\n",
    "        \n",
    "        # Final projection and residual\n",
    "        out = self.proj(out)\n",
    "        return x + out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "206c3440",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, channels, context_dim, num_heads=8, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadSelfAttention(channels, num_heads, dropout)\n",
    "        self.cross_attn = MultiHeadCrossAttention(channels, context_dim, num_heads)\n",
    "\n",
    "        num_groups = min(8, channels)\n",
    "        while channels % num_groups != 0:\n",
    "            num_groups -= 1\n",
    "    \n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.GroupNorm(num_groups, channels),\n",
    "            nn.Conv2d(channels, channels * 4, 1),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(channels * 4, channels, 1),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        x = self.self_attn(x)\n",
    "        x = self.cross_attn(x, context)\n",
    "        return x + self.ffn(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ffabb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Using sinusoidal positional embeddings for time steps\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "        if self.dim % 2 == 1:  # zero pad\n",
    "            emb = F.pad(emb, (0,1,0,0))\n",
    "        return emb\n",
    "\n",
    "\n",
    "# Enhanced ResNet Block with optional attention\n",
    "class ResnetBlockWithAttention(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_emb_dim, context_dim, layer_context_dim = 64, use_attention=False):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.norm1 = nn.GroupNorm(8, out_channels)\n",
    "\n",
    "        self.time_mlp = nn.Linear(time_emb_dim, out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.norm2 = nn.GroupNorm(8, out_channels)\n",
    "\n",
    "        self.layer_mlp = nn.Sequential(\n",
    "            nn.Linear(layer_context_dim, out_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(out_channels, out_channels)\n",
    "        ) \n",
    "\n",
    "        self.activation = nn.SiLU()\n",
    "        \n",
    "        # Add transformer block if specified\n",
    "        self.use_attention = use_attention\n",
    "        if use_attention:\n",
    "            self.attention = TransformerBlock(out_channels, context_dim, num_heads=8)\n",
    "\n",
    "        # Shortcut connection\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "    \n",
    "    def forward(self, x, t, context_emb, layer_context=None):\n",
    "        h = self.conv1(x)\n",
    "        h = self.norm1(h)\n",
    "        h = self.activation(h)\n",
    "        \n",
    "        # Add time embedding\n",
    "        h += self.time_mlp(t)[:, :, None, None]\n",
    "\n",
    "        # Add layer context if provided\n",
    "        if layer_context is not None:\n",
    "            h += self.layer_mlp(layer_context)[:, :, None, None]\n",
    "\n",
    "        h = self.activation(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.norm2(h)\n",
    "        h = self.activation(h)\n",
    "        \n",
    "        # Apply attention if enabled\n",
    "        if self.use_attention:\n",
    "            h = self.attention(h, context_emb) # eventually add layer_context here too\n",
    "        \n",
    "        return h + self.shortcut(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, model_channels=128, context_dim=512, \n",
    "                 attention_resolutions=[8, 16]):\n",
    "        \"\"\"\n",
    "        attention_resolutions: list of resolutions (H, W) where attention should be applied\n",
    "        For 32x32 images: resolution 16 means we apply attention at 16x16 feature maps\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model_channels = model_channels\n",
    "        self.attention_resolutions = attention_resolutions\n",
    "        \n",
    "        # Time embedding\n",
    "        time_embed_dim = model_channels * 4\n",
    "        self.time_embed = nn.Sequential(\n",
    "            SinusoidalPosEmb(model_channels),\n",
    "            nn.Linear(model_channels, time_embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_embed_dim, time_embed_dim),\n",
    "        )\n",
    "\n",
    "        # Input\n",
    "        self.input_conv = nn.Conv2d(in_channels, model_channels, 3, padding=1)\n",
    "        \n",
    "        # Down blocks with attention at specific resolutions\n",
    "        # For 32x32 input: 32 -> 16 -> 8\n",
    "        self.down_block1 = ResnetBlockWithAttention(\n",
    "            model_channels, model_channels * 2, time_embed_dim, context_dim,\n",
    "            use_attention=(32 in attention_resolutions)\n",
    "        )\n",
    "        self.down_block2 = ResnetBlockWithAttention(\n",
    "            model_channels * 2, model_channels * 4, time_embed_dim, context_dim,\n",
    "            use_attention=(16 in attention_resolutions)\n",
    "        )\n",
    "        self.down_block3 = ResnetBlockWithAttention(\n",
    "            model_channels * 4, model_channels * 4, time_embed_dim, context_dim,\n",
    "            use_attention=(8 in attention_resolutions)\n",
    "        )\n",
    "        \n",
    "        self.downsample1 = nn.MaxPool2d(2)\n",
    "        self.downsample2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Middle block with attention (always at lowest resolution)\n",
    "        self.mid_block = ResnetBlockWithAttention(\n",
    "            model_channels * 4, model_channels * 4, time_embed_dim, context_dim,\n",
    "            use_attention=True\n",
    "        )\n",
    "        \n",
    "        # Up blocks with attention\n",
    "        self.up_block1 = ResnetBlockWithAttention(\n",
    "            model_channels * 4, model_channels * 4, time_embed_dim, context_dim,\n",
    "            use_attention=(8 in attention_resolutions)\n",
    "        )\n",
    "        self.up_block2 = ResnetBlockWithAttention(\n",
    "            model_channels * 4 + model_channels * 4, model_channels * 2, time_embed_dim, context_dim,\n",
    "            use_attention=(16 in attention_resolutions)\n",
    "        )\n",
    "        self.up_block3 = ResnetBlockWithAttention(\n",
    "            model_channels * 2 + model_channels * 2, model_channels, time_embed_dim, context_dim,\n",
    "            use_attention=(32 in attention_resolutions)\n",
    "        )\n",
    "        \n",
    "        self.upsample1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Output\n",
    "        self.output_conv = nn.Conv2d(model_channels, in_channels, 3, padding=1)\n",
    "\n",
    "    def forward(self, x, t, context, layer_context=None):\n",
    "        # Time embedding\n",
    "        time_emb = self.time_embed(t)\n",
    "\n",
    "        # Input\n",
    "        h = self.input_conv(x)\n",
    "\n",
    "        # Downsampling with skip connections\n",
    "        h1 = self.down_block1(h, time_emb, context)\n",
    "        h = self.downsample1(h1)\n",
    "        h2 = self.down_block2(h, time_emb, context)\n",
    "        h = self.downsample2(h2)\n",
    "        h3 = self.down_block3(h, time_emb, context)\n",
    "\n",
    "        # Middle\n",
    "        h = self.mid_block(h3, time_emb, context)\n",
    "\n",
    "        # Upsampling with skip connections\n",
    "        h = self.up_block1(h, time_emb, context)\n",
    "        h = self.upsample1(h)\n",
    "        h = torch.cat([h, h2], dim=1)\n",
    "        h = self.up_block2(h, time_emb, context)\n",
    "        h = self.upsample2(h)\n",
    "        h = torch.cat([h, h1], dim=1)\n",
    "        h = self.up_block3(h, time_emb, context)\n",
    "\n",
    "        # Output\n",
    "        return self.output_conv(h)\n",
    "\n",
    "\n",
    "\n",
    "class ExponentialMovingAverage:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        self.backup = {}\n",
    "\n",
    "        # Initialize shadow weights\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "\n",
    "    def apply_shadow(self):\n",
    "        # Backup current parameters\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.backup[name] = param.data.clone()\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfad340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward diffusion that creates a corrupted input\n",
    "class ForwardDiffusion():\n",
    "    def __init__(self, timesteps=1000, beta_start=1e-4, beta_end=0.02):\n",
    "        self.timesteps = timesteps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        \n",
    "        self.betas = torch.linspace(beta_start, beta_end, timesteps)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alpha_hats = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "        # Precompute sqrt_alpha_hats and sqrt_one_minus_alpha_hats for efficiency\n",
    "        self.sqrt_alpha_hats = torch.sqrt(self.alpha_hats)\n",
    "        self.sqrt_one_minus_alpha_hats = torch.sqrt(1 - self.alpha_hats)\n",
    "\n",
    "        # ensure all tensors are on the same device\n",
    "        self.betas = self.betas.to(device)\n",
    "        self.alphas = self.alphas.to(device)\n",
    "        self.alpha_hats = self.alpha_hats.to(device)\n",
    "        self.sqrt_alpha_hats = self.sqrt_alpha_hats.to(device)\n",
    "        self.sqrt_one_minus_alpha_hats = self.sqrt_one_minus_alpha_hats.to(device)\n",
    "\n",
    "    def forward(self, x0, t, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x0)\n",
    "        \n",
    "        sqrt_alpha_hat = self.sqrt_alpha_hats[t].view(-1, 1, 1, 1).to(x0.device)\n",
    "        sqrt_one_minus_alpha_hat = self.sqrt_one_minus_alpha_hats[t].view(-1, 1, 1, 1).to(x0.device)\n",
    "        \n",
    "        xt = sqrt_alpha_hat * x0 + sqrt_one_minus_alpha_hat * noise\n",
    "        return xt, noise\n",
    "\n",
    "    def get_variance_schedule(self,t):\n",
    "        # Return the variance at timestep t (posterior variance)\n",
    "\n",
    "        if t == 0:\n",
    "            return self.betas[0]\n",
    "        else:\n",
    "            alpha_hat_t = self.alpha_hats[t]\n",
    "            alpha_hat_t_minus_1 = self.alpha_hats[t - 1]\n",
    "            return self.betas[t] * (1 - alpha_hat_t_minus_1) / (1 - alpha_hat_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "050f6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2d difussion trainer\n",
    "class DiffusionTrainer2D:\n",
    "    def __init__(self, model, diffusion, scheduler):\n",
    "        self.model = model # this is the noise predicting model (denoiser)\n",
    "        self.diffusion = diffusion # this is the forward diffusion process (noise addition)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "        self.scheduler = scheduler # can be None its the learning rate scheduler\n",
    "\n",
    "    def train_step(self, x0, context):\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        batch_size = x0.size(0)\n",
    "        t = torch.randint(0, self.diffusion.timesteps, (batch_size,), device=x0.device).long()\n",
    "        xt, noise = self.diffusion.forward(x0, t)\n",
    "\n",
    "        predicted_noise = self.model(xt, t.float(), context)\n",
    "        loss = F.mse_loss(predicted_noise, noise)\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.scheduler is not None:\n",
    "            self.scheduler.step()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def sample(self, context, shape, device):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn(shape, device=device)\n",
    "            for t in reversed(range(self.diffusion.timesteps)):\n",
    "                t_batch = torch.full((shape[0],), t, device=device, dtype=torch.float32)\n",
    "                predicted_noise = self.model(x, t_batch, context)\n",
    "\n",
    "                alpha_t = self.diffusion.alphas[t]\n",
    "                alpha_hat_t = self.diffusion.alpha_hats[t]\n",
    "                beta_t = self.diffusion.betas[t]\n",
    "\n",
    "                if t > 0:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "\n",
    "                x = (1 / torch.sqrt(alpha_t)) * (x - ((1 - alpha_t) / torch.sqrt(1 - alpha_hat_t)) * predicted_noise) + torch.sqrt(beta_t) * noise\n",
    "\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d8fdec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialMovingAverage:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        self.backup = {}\n",
    "\n",
    "        # Initialize shadow weights\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "\n",
    "    def apply_shadow(self):\n",
    "        # Backup current parameters\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.backup[name] = param.data.clone()\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f4f66958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "# sample dataset of grayscale cifar10 images\n",
    "class GrayscaleCIFAR10(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, download=True):\n",
    "        self.cifar10 = datasets.CIFAR10(root=root, train=train, transform=transform, download=download)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cifar10)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.cifar10[idx]\n",
    "        # Convert to grayscale\n",
    "        img = img.convert(\"L\")\n",
    "        img = np.array(img).astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "        img = torch.from_numpy(img).unsqueeze(0)  # Add channel dimension\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ba78f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ad.msoe.edu/benzshawelt/Kedziora/kedziora_research/.conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(GrayscaleCIFAR10(root='./data'), batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1fd5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 80,552,065\n",
      "Epoch 1/10, Average Loss: 0.0896\n",
      "Epoch 2/10, Average Loss: 0.0341\n",
      "Epoch 3/10, Average Loss: 0.0318\n",
      "Epoch 4/10, Average Loss: 0.0303\n",
      "Epoch 5/10, Average Loss: 0.0301\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAH4CAYAAAB9k1VdAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAATdNJREFUeJzt3XuUl2W9///3cBpxgGFgBhgGGIajIpCK6Q5hS6KLFEwrdduuAHdF28qsVrtlp5Ur27Y6mS0z1m7tHZm1V+UhbXsGw8wyNRXzhJzPh2EGhjMoeH//6Mf8GLlfL5gbPl4Vz8da/uF1z/WZ677u674vPvB+3++yLMuyAAAAb7kOqQcAAMDxik0YAIBE2IQBAEiETRgAgETYhAEASIRNGACARNiEAQBIhE0YAIBE2IQBAEiETfhvxE9+8pMoKyuLP//5z6mH8pYqxXlfd911UVZWdsw+780OjPnAf01NTe3+jBUrVkRZWVn85Cc/OfYDTKA913HSpEkxadKko/p9M2fOjMGDBx/VZ6A0Zs6cGd26dWt3vwULFrS5r+64444SjO5vz3GzCb/5wfnm//70pz+lHuJRcee3YcOGY/q7it5k/2i+973vxW233Rbdu3dvbZs5c+ZRbzBvhQN/CHj00UcL9R88eHBcd911x3RMR+to/lAzadKkmDlz5jEdz8FuuOGGuPvuuw9pP3DfFpF3De+///6/ueuivHnO6+vr47bbbosvfvGL6QaVQKfUA3irfe1rX4uGhoZD2ocNG5ZgNMde3vn17NkzzWD+wV1yySV8Gyvg4YcfTj2Et9wNN9wQl156aVxyySUl/T33339/3HLLLX83G/HBqqqq4oMf/GA8+uijccMNN6QezlvmuNuEL7jggjjjjDNSD6Nk/tHPD0dn37598cYbbyQdQ5cuXQ77M3v27IkuXbpEhw7HzV/WveUOrIUjuR4oHVb4mxz4K57vfOc78b3vfS/q6+uja9eucc4558SLL754yM//9re/jYkTJ0ZFRUX07NkzLr744njllVcO+bm1a9fGhz/84ejfv3+Ul5dHQ0NDXHXVVfHaa6+1+bm9e/fGZz/72aipqYmKiop4z3veE5s2bWrXOWzfvj3279/fvhM/xlauXBkf//jHY+TIkdG1a9fo3bt3XHbZZbFixYrcn9+1a1d87GMfi969e0ePHj1i+vTpsWXLlkN+7oEHHmid7+7du8fUqVPjpZdeOux45s6dGxMmTIiePXtGt27dYuTIkYf8tdeqVati4cKFhc7XaWlpiZkzZ0ZlZWX07NkzZsyYES0tLbk/u3Dhwrj00kujV69eccIJJ8QZZ5wRv/nNb3I/89Of/nQMHDgwysvLY9iwYfHNb36zzQZ78Fq+6aabYujQoVFeXh4vv/zyMT/HA47kOr7534QfffTRKCsri1/84hfx5S9/Oerq6uLEE0+Mbdu2RUTE3XffHaNHj44TTjghRo8eHb/+9a9LNv6D7dmzJ6677roYMWJEnHDCCVFbWxvvfe97Y+nSpa0/853vfCfGjx8fvXv3jq5du8a4ceMO+bfMsrKy2LlzZ9x6662t/0RUir/6njlzZtxyyy2tv/PAfxF+LRz4K/E335sHrsub/8niySefjAsvvDCqqqqioqIixo4dG9///vft2BYsWBA1NTUxadKk2LFjxzE7538Ex9034a1btx4SSFNWVha9e/du0/bTn/40tm/fHp/4xCdiz5498f3vfz/OPffceOGFF6Jv374RETFv3ry44IILYsiQIXHdddfF7t274+abb46zzz47nn322da/qly3bl2ceeaZ0dLSErNmzYqTTjop1q5dG3fccUfs2rWrzZ9Er7766qiqqoqvfvWrsWLFirjpppvik5/8ZPzyl788ovN75zvfGTt27IguXbrElClT4rvf/W4MHz78KGasmKeffjr++Mc/xhVXXBEDBgyIFStWxOzZs2PSpEnx8ssvx4knntjm5z/5yU9Gz54947rrrotXX301Zs+eHStXrmx9EERE3HbbbTFjxoyYMmVKfPOb34xdu3bF7NmzY8KECfHcc8/Jvxp+6aWXYtq0aTF27Nj42te+FuXl5bFkyZL4wx/+0Obnpk+fHr/73e/iWFb3zLIsLr744nj88cfj3//93+Pkk0+OX//61zFjxozccZ599tlRV1cX1157bVRUVMSvfvWruOSSS+LOO++M97znPRHx143unHPOibVr18bHPvaxGDRoUPzxj3+ML3zhC7F+/fq46aab2nzunDlzYs+ePTFr1qwoLy+PXr16lezb8JFcR+X666+PLl26xOc+97nYu3dvdOnSJR5++OF43/veF6NGjYpvfOMb0dzcHFdeeWUMGDCgJOM/YP/+/TFt2rR45JFH4oorrohrrrkmtm/fHnPnzo0XX3wxhg4dGhER3//+9+Pd7353fOADH4jXXnstfvGLX8Rll10W9957b0ydOjUi/rpuP/KRj8SZZ54Zs2bNioho7X8sfexjH4t169bF3Llz47bbbsv9mby10B5z586NadOmRW1tbVxzzTXRr1+/eOWVV+Lee++Na665JrfP008/HVOmTIkzzjgj7rnnnujatWu7z+0fWnacmDNnThYRuf+Vl5e3/tzy5cuziMi6du2arVmzprX9ySefzCIi+8xnPtPaduqpp2Z9+vTJmpubW9uef/75rEOHDtn06dNb26ZPn5516NAhe/rppw8Z1xtvvNFmfOedd15rW5Zl2Wc+85msY8eOWUtLiz2/X/7yl9nMmTOzW2+9Nfv1r3+dffnLX85OPPHErLq6Olu1alU7ZurwZsyYkVVUVNif2bVr1yFtTzzxRBYR2U9/+tPWtgPnPW7cuOy1115rbf/Wt76VRUR2zz33ZFmWZdu3b8969uyZffSjH23zmRs2bMgqKyvbtH/1q1/NDl7a3/ve97KIyDZt2mTHfM4552RHckscGPPy5csP+7N33313FhHZt771rda2ffv2ZRMnTswiIpszZ05r++TJk7MxY8Zke/bsaW174403svHjx2fDhw9vbbv++uuzioqKbNGiRW1+17XXXpt17Nix9XofWMs9evTIGhsbDzvWo3Gk1zHL/jrP55xzTuv/z58/P4uIbMiQIYesm1NPPTWrra1ts/4ffvjhLCKy+vr6kp3Pj3/84ywishtvvPGQYwffn28e72uvvZaNHj06O/fcc9u0V1RUZDNmzCjJWA/2iU98IncNu7Wg1vOB6zJ//vwsy/66bhsaGrL6+vpsy5YtbX724Dk5+Pnw+OOPZz169MimTp3aZl07B37v7bfffkQ///fuuPvr6FtuuSXmzp3b5r8HHnjgkJ+75JJLoq6urvX/zzzzzDjrrLPi/vvvj4iI9evXx4IFC2LmzJlt/jQ5duzYOP/881t/7o033oi77747Lrrootx/q33zt4NZs2a1aZs4cWLs378/Vq5cac/r8ssvjzlz5sT06dPjkksuieuvvz4eeuihaG5ujv/8z/88gpk5tg7+0+7rr78ezc3NMWzYsOjZs2c8++yzh/z8rFmzonPnzq3/f9VVV0WnTp1a53Hu3LnR0tIS73//+6Opqan1v44dO8ZZZ50V8+fPl2M5EJh2zz332G+Ajz766DH9Fhzx10CZTp06xVVXXdXa1rFjx7j66qvb/NzmzZvjt7/9bVx++eWxffv21vNrbm6OKVOmxOLFi2Pt2rUREXH77bfHxIkTo6qqqs1cnHfeebF///547LHH2nz2+973vqipqTmm56Uc7jo6M2bMaLNuDtxjM2bMiMrKytb2888/P0aNGnVsB/4md955Z1RXVx9ynSLa3rMHj3fLli2xdevWmDhxYu4a/1twNGvhueeei+XLl8enP/3pQ4I98/6WY/78+TFlypSYPHly3HXXXVFeXl7o9/6jO+7+OvrMM888osClvL/CHTFiRPzqV7+KiGjdFEeOHHnIz5188snx0EMPxc6dO2PHjh2xbdu2GD169BGNb9CgQW3+v6qqKiIi999HD2fChAlx1llnxbx58+zPbd26NXbv3t36/126dGn3X1O92e7du+Mb3/hGzJkzJ9auXdtmc9u6deshP//m+e7WrVvU1ta2/jvV4sWLIyLi3HPPzf19PXr0kGP5l3/5l/jv//7v+MhHPhLXXnttTJ48Od773vfGpZdeWvLAn5UrV0Ztbe0hKV1vXjdLliyJLMviK1/5SnzlK1/J/azGxsaoq6uLxYsXx1/+8hf5MG1sbGzz/3nZAKVyuOvovHmcB+6xvHtx5MiRJd3oli5dGiNHjoxOnfwj8t57742vf/3rsWDBgti7d29reynz1I/G0ayFA/8WfiTPsj179sTUqVNj3Lhx8atf/eqw83g8Y2b+xnTs2DG3veg3tIEDB8arr75qf+aaa66JW2+9tfX/zznnnML5owdcffXVMWfOnPj0pz8d73jHO6KysjLKysriiiuuKPTvkQf63HbbbdGvX79DjrubvGvXrvHYY4/F/Pnz47777osHH3wwfvnLX8a5554bDz/8sJzzt9KB8/vc5z4XU6ZMyf2ZA2l0b7zxRpx//vnx+c9/PvfnRowY0eb//17+De7vZZwH/P73v493v/vd8c///M/xwx/+MGpra6Nz584xZ86c+N///d/Uw8uVN8fqDwxHE9xZXl4eF154Ydxzzz3x4IMPxrRp0wp/1j86NmHhwDevgy1atKg1+Ke+vj4iIneDW7hwYVRXV0dFRUV07do1evTokRtZ/VZYtmzZYf/66fOf/3x88IMfbP3/A9++j8Ydd9wRM2bMiO9+97utbXv27JFRwYsXL453vvOdrf+/Y8eOWL9+fVx44YUR8f8HsvTp0yfOO++8do+nQ4cOMXny5Jg8eXLceOONccMNN8SXvvSlmD9/fqHPO1L19fXxyCOPxI4dO9p8G37zuhkyZEhERHTu3Pmw4xk6dGjs2LGjpOMu6nDXsT0O3GN59+Lh/mB5tIYOHRpPPvlkvP76623+ev1gd955Z5xwwgnx0EMPtfmr1jlz5hzys2/VN+Miv+fA/f7me/PN/wR24B588cUXD7v2ysrK4uc//3lcfPHFcdlll8UDDzzwd/ESmxSOu38TPlJ3331367/BRUQ89dRT8eSTT8YFF1wQERG1tbVx6qmnxq233tpm8b744ovx8MMPtz50OnToEJdcckn83//9X+4r/Y7Vv0HmpTHdf//98cwzz8S73vUu23fUqFFx3nnntf43bty4ox5Px44dDzm3m2++Wf7p+kc/+lG8/vrrrf8/e/bs2LdvX+t8T5kyJXr06BE33HBDm587wKVxbd68+ZC2U089NSKizV8hliJF6cILL4x9+/bF7NmzW9v2798fN998c5uf69OnT0yaNCn+67/+K9avX3/I5xx8fpdffnk88cQT8dBDDx3ycy0tLbFv375jeAbtc7jr2B4H32MH/xPG3LlzS5pmFfHXfzttamqKH/zgB4ccO7CuO3bsGGVlZW3W9IoVK3LfjFVRUSH/AHosVVRURMShG6pzYHM9OJZg//798aMf/ajNz51++unR0NAQN9100yGfn/cc69KlS9x1113x9re/PS666KJ46qmnjnhMx5Pj7pvwAw88kPugHT9+fOu3kYi//tXfhAkT4qqrroq9e/fGTTfdFL17927zV4Df/va344ILLoh3vOMd8eEPf7g1RamysrLNG2tuuOGGePjhh+Occ86JWbNmxcknnxzr16+P22+/PR5//PFj8kar8ePHx2mnnRZnnHFGVFZWxrPPPhs//vGPY+DAgSV5Ddzrr78eX//61w9p79WrV3z84x+PadOmxW233RaVlZUxatSoeOKJJ2LevHmHpIId8Nprr8XkyZPj8ssvj1dffTV++MMfxoQJE+Ld7353RPz133xnz54dH/rQh+L000+PK664ImpqamLVqlVx3333xdlnn537wIz461vEHnvssZg6dWrU19dHY2Nj/PCHP4wBAwbEhAkTWn+uFClKF110UZx99tlx7bXXxooVK2LUqFFx11135f67+C233BITJkyIMWPGxEc/+tEYMmRIbNy4MZ544olYs2ZNPP/88xER8R//8R/xm9/8JqZNmxYzZ86McePGxc6dO+OFF16IO+64I1asWBHV1dXtHuuKFSuioaEhZsyYUfj1j4e7ju31jW98I6ZOnRoTJkyIf/u3f4vNmzfHzTffHKeccsoR5ZuWlZUV+ueV6dOnx09/+tP47Gc/G0899VRMnDgxdu7cGfPmzYuPf/zjcfHFF8fUqVPjxhtvjHe9613xr//6r9HY2Bi33HJLDBs2LP7yl7+0+bxx48bFvHnz4sYbb4z+/ftHQ0NDnHXWWbm/+yc/+UlceeWVMWfOnHbnEx/4A/SnPvWpmDJlSnTs2DGuuOIK2+eUU06Jf/qnf4ovfOELsXnz5ujVq1f84he/OOQPcx06dIjZs2fHRRddFKeeempceeWVUVtbGwsXLoyXXnop9w+FXbt2jXvvvTfOPffcuOCCC+J3v/vdEcfHHDeSxWW/xVyKUhyUKnIglP/b3/529t3vfjcbOHBgVl5enk2cODF7/vnnD/ncefPmZWeffXbWtWvXrEePHtlFF12Uvfzyy4f83MqVK7Pp06dnNTU1WXl5eTZkyJDsE5/4RLZ3794243tzGtOb0wSUL33pS9mpp56aVVZWZp07d84GDRqUXXXVVdmGDRuKTZgxY8YMOY9Dhw7NsizLtmzZkl155ZVZdXV11q1bt2zKlCnZwoULs/r6+japGgfO+3e/+102a9asrKqqKuvWrVv2gQ98oE3q1wHz58/PpkyZklVWVmYnnHBCNnTo0GzmzJnZn//859afeXOK0iOPPJJdfPHFWf/+/bMuXbpk/fv3z97//vcfkuJTihSlLMuy5ubm7EMf+lDWo0ePrLKyMvvQhz6UPffcc4ekKGVZli1dujSbPn161q9fv6xz585ZXV1dNm3atOyOO+5o83Pbt2/PvvCFL2TDhg3LunTpklVXV2fjx4/PvvOd77SmCB28lo/ECy+8kEVEdu211x7Rzx+sPddRpSiplJQ777wzO/nkk7Py8vJs1KhR2V133ZXNmDHjsClK27dvzyIiu+KKK9p9Pln21/SjL33pS1lDQ0PWuXPnrF+/ftmll16aLV26tPVn/ud//icbPnx4Vl5enp100knZnDlzDll/WZZlCxcuzP75n/8569q1axYRNl3p5ptvziIie/DBB9s95n379mVXX311VlNTk5WVlbWO43BrYenSpdl5552XlZeXZ3379s2++MUvZnPnzs199jz++OPZ+eefn3Xv3j2rqKjIxo4dm918882tx/NSGJuamrJRo0Zl/fr1yxYvXmzP4XhLUTpuNuEj1d4HF44/BzacZ599Ntu0aVObHMm/Z7fccktWUVFRkj+4pXDfffdlZWVl2V/+8pfUQ2mXyy67LHv729+eehhvuX379mWbNm1qza0/Xjbh4+6vo4Fj5fTTT4+Iv/57bZG//v1bM3/+/PjUpz7V+ka4v3fz58+PK664IsaMGZN6KEcsy7J49NFH42c/+1nqobzlXnjhhTjttNNSD+MtxyYMtNOUKVNi7ty5rf9/8Isk/p7dfvvtqYdwTH37299OPYR2KysrOyTP+3gxbNiwNvfV2LFjE47mrcMmDLRTbW1t1NbWph4G8A+lW7duf5Npd6VWlmXH+D19AADgiJAnDABAImzCAAAkwiYMAEAiRxyY9bdaFQQAgL9FRxJyxTdhAAASYRMGACARNmEAABJhEwYAIBE2YQAAEmETBgAgETZhAAASYRMGACARNmEAABJhEwYAIBE2YQAAEmETBgAgkSMu4FDEl7/8ZXmsT58+ue1vvPGG7FNeXi6PdeiQ/+cJ1R4RsW/fvnb/nhNOOEEeU3r16iWP9ejRo13tERHdu3eXx7p06ZLb/tprr8k+6pg71127dsljW7ZsyW3funWr7LNmzZrc9r1798o+7ph6cfrOnTtlH7Ue3JpUfRzXZ/fu3bntP/jBD9r9eyIiPvrRj+a2d+qkb/3OnTvntrt7SV3zCH2+6lwj9D04atQo2cddW7WW3RpX960rZuPmSN1ntbW1so9a4+r56X6P467fyy+/nNvuzvWVV16Rx9atW5fb7tbDnj17ctvVWo2IeMc73iGPqWvY0tIi+/z85z+Xx44G34QBAEiETRgAgETYhAEASIRNGACARNiEAQBIhE0YAIBESpqi1LNnT3lMpZDs379f9nFpFSeeeOIRj+uAjh07tqs9wo9PcePu2rVrbntlZaXs485VpWm4catUA3WNIvw5qRSJHTt2yD6rVq3KbXcpJC6VTKUuuLlT6SBuHl5//XV5TM25S+1w6VBFqLVcZB271By1jiP0mnSpWuq6L1iwQPZxqT7qfqqqqmp3H5fG4uZh8eLFue0u3UilI7oURre+tm3bJo8pmzZtym3v16+f7NO7d295TKUoubGpFKq3ve1tsk9NTY08tn79+tx2tx5KhW/CAAAkwiYMAEAibMIAACTCJgwAQCJswgAAJFLS6GgX/agiDF3UrSuEoCJl3UvdVRSvi6B141PRo67QgIoKVi8sj4iorq6Wx1QBBxdJrCJyi0bqqjlyY1Brxc2De3m7ehm8i2ZWc+fG4CJR1fhUtGmEj4ovQq09lwGgIpPV/EQUK4zhInzVWnFjqKiokMcGDx6c216kIIsb95IlS+QxtSZdJHF9fX1uu1uTa9eulcdUpL96DkXoSGI3d64ghLov3PUbNGhQbvtpp50m+7hoa5WpUSRr4GjxTRgAgETYhAEASIRNGACARNiEAQBIhE0YAIBE2IQBAEgkWQEHlf7iUoBcyow65tJY1DH3ono3BpX24fps3749t129uD3Cp7go7vNUioRLMXPnpFIXXOqXetm6So+I8Klfagzupe7quhcpThCh05e6desm+7jfVYRak+73qD4uvculPKn15cag0gfd73Gft2jRotz2xsZG2UetL5cq2dTUJI+pAhNFUu02bNgg+7hCKSoFx4172LBhue3uGeDSuHbt2pXbvnnzZtlHzZGbO5fOptaKeh6XEt+EAQBIhE0YAIBE2IQBAEiETRgAgETYhAEASIRNGACAREqaouRC+RWX8qEqgETo1AU3BvV5rvqGC6NXYfmuepBK+3BpSG586pzOOOMM2Uel0rhULXed1BwtX75c9lFVV1yVIldJRnFpc0W4a6vSS9wYilT1cVTKn5tXtYbcuRZJeSqS5uaq3LhzWrdunTymqPN16TcuLWby5Mm57a6KkqqI5FJpFixYII+p9CVX9Wj48OG57e4Z5dLZFHdtVXqX6+OqMvXt2ze33e0xpcI3YQAAEmETBgAgETZhAAASYRMGACARNmEAABIpaXS0i35UL/NftWqV7OMi4VQkqouYVBF8rjCAi0psbm7ObXeRo6pIgotMVi9Aj9DFAdw8qGhr93vc+NTL91taWmQfdayyslL2cZGMagwq2jTCF3dQXDSsGp8rjHGsozPVPLgIX8UVV3Ev0ldcMQYVmezuTRct36dPn9x290xR18Jdc3dOqhiJGluEjqR3mQZLly6Vx9Tzq3///rKPipx2hSKKFH+pqqqSfdTzZvXq1bJPdXW1PDZkyJDcdjfuUuGbMAAAibAJAwCQCJswAACJsAkDAJAImzAAAImwCQMAkEhJU5RUGlJERPfu3XPbBwwYUOjzVOrCypUrZR8V/q/SnSIiBg8eLI+pdAcXer9mzZrcdvdC9bq6OnlMpdmo1KUInTLgXtjv0kFUCoe7tirdoWhajEoLcylA6pzcuap1HKHH59KDiqT6OOol+y5tTl0nNzb3wn61jtz9rK6TS5tz961KHXIph1u3bm3X2CJ82o4qbOIKDRR5rtXX18tjzz//fG77smXLZB+1Xt08uJRIlW7kCpuoggsuJcwVQ1FrxaWflQrfhAEASIRNGACARNiEAQBIhE0YAIBE2IQBAEikpNHRLpqyX79+ue1Dhw6VfYoULnARmCrq1UUrugg+FVnnomtVBKYrfuEiOnv37p3b7iIZ1UvLXcSro16c7l6OrtaKi1Z0EZhqzt08qKhN18fNkernos7dORWh5k8VdojQ18LdF+7aqn7u+aAKerjf47IQXKEGRRU2cc8UdT9H6Ehn10fd6+451NDQII+piOFnnnlG9lHXzxXTcFHLKvPDZX2oe9MVv3BjUFHsrmBMqfBNGACARNiEAQBIhE0YAIBE2IQBAEiETRgAgETYhAEASKSkKUqvvPKKPKZScE455RTZx72QW4Wjuxfsq/QNl87Q3Nwsj6n0IJdupI65cbuX76tUrZ07d8o+al7duF2ajUovcekE48aNy213aQbuhf3uOikq9cStO5U6EaHnz82r+7wiVAEMl+rT2NiY296/f3/ZR639CJ1m41Jc1LGi6WLq2rqCC2rtueeDu29Vas7y5ctlH1WQxY3Bzau6hm5Nqt/lroUbn3pGqedGhE5PdQVe3DNKpei561cqfBMGACARNmEAABJhEwYAIBE2YQAAEmETBgAgETZhAAASKWmKkqs2olJmXCqNC4lXx1zFIZXi4lIdXPWZlStX5rYPHDhQ9lGVZNw8uPB/VYXHpS2otBgX/u8q4PTq1Su33YX/jx07NrfdpS249CXVz6UuNTU15ba7NBaX6qPWiltfx7qKkkqvcmtIrYciqXYRuhqRqwSkxuDS89yaVNfCrSG1XlUKV8Sxr6ql7kGV5hPhr6165rkKWUWek+oZEKGvk6smpa6F2xPcelDpki7tsVT4JgwAQCJswgAAJMImDABAImzCAAAkwiYMAEAiJY2Otr9YRP2tXr1a9nGRoypSz0Ueqj5FIokj9Ava16xZI/uMHDkyt129uD2iWFSwmzsV/esiiV2U6p49e3LbXcS3ioysqqqSfdw5qahJF82sxu2iTV20vIrOdJGoxzo6Wq3Juro62WfIkCG57S66vUikrPs8dZ+pSOsIH6GtIt/79evX7s9zUbxurai17J4pah1v3LhR9lm7dq08pp4d6ppH6Ah7t/ZdBPkjjzyS266uUURE3759c9vdGnIR2mpe3b1ZKnwTBgAgETZhAAASYRMGACARNmEAABJhEwYAIBE2YQAAEilpipIrnqDCxzdv3iz7uIICKmWmSBEC9xJv91LwysrK3HZXAEClE7hxF3lJvEuDUClZ69atk33Wr18vjy1atCi33aUoqTG4FDN3LRoaGnLbXcqTKjjSo0cP2WfTpk3ymEoHcYVNjjWV2uFS4Kqrq3Pb3Xz/6U9/ksdUGolbkyotRqWRRfgUF5Wq5daDeg6o+zwiokuXLvKY4tKu1LNjw4YNso87p8GDB+e2jxkzRvZRz1Y3BpfGpdKAVAEc97vU+o7wz0nFrclS4ZswAACJsAkDAJAImzAAAImwCQMAkAibMAAAiZQ0OtpFp6koaBcV7KISVXSteyG+OqYijCP8C9pVZJ0bg3oRuxuDO6bmz0X9qShQF7XpXt5ehIqWd/PtonV79uyZ266ibiN05K2L9HSR9EVevu8isYtQEdouyli9fN8V7XD3rbqG3bp1k32KRLa6LAS1VlzRhz59+uS2q0jrCF/8Rd0ztbW17f68k046SfYZPXq0PDZgwIDcdlcURq1x90xR2QkREbt27cptdwUX1Jp88cUXZR+3xtU8FIluP1p8EwYAIBE2YQAAEmETBgAgETZhAAASYRMGACARNmEAABIpaYrSq6++Ko+pl9i70HYXwq6KA7j0EpVW4QoNuDQNlUKl0mUidLi+C693Vq9endvuUjFU6oTr48Y3cODAdvdRKSQuvWvVqlXymEqLcakYzc3Nue0tLS2yj0vTUMUnXBqSG18R6tq6lCJVCEEVYojwaTYq7cOluan7ds2aNbKPK/ah7k13LdQa6t27t+zj0s/Uc8ClxajnpEtTdPOg5tU919TvKpLuF6HPyaWYqfE99dRTso8rMqPWq7svSoVvwgAAJMImDABAImzCAAAkwiYMAEAibMIAACTCJgwAQCIljcd24d4q7cOlxbhQfhWO7lKUKioqcttdlZS6ujp5TFUbKVL1yKU6uAozKszfXQuVKuLSN1xFK5W64NJ51Plu2rRJ9lm4cKE8ptJpXAqQSp1w43ZVntQ8qHUXcexTlFQVHlftR1WYUVWFInz6oDonN6+qytqGDRtkH3efqTH0799f9tm+fXtue9EUM1U1yj3z1BhculgR+/btk8dUypNLhXLpRirFS6XGRehUzuHDh8s+7t5UVZncvVkqfBMGACARNmEAABJhEwYAIBE2YQAAEmETBgAgkZJGR7sIPhVF6CLaihRWUFF1ETry0EVZFomUVZGerk/RIhIqctONQV0n91J+FxmpIp1dBKaaB3eugwcPlsdUxKm7fkWimd05Ka5wgYsqLUJFLa9du1b22bZtW277+PHjZR91L0Xotbd48WLZR2VCuKjuFStWtPvzXIEQFc3ssjRcsQ/1zHOfp7IaXBS2e36p9eoKLqh73f0e97xR96CbB3XM3Zvu+aWer24dlwrfhAEASIRNGACARNiEAQBIhE0YAIBE2IQBAEiETRgAgERKmqLkwv9rampy213ovUvbUdTLwiMili5dmtvuih0USWlwaScqJL6qqqrQGFTBClf0QaUauHQLF/6vjrkXtBcpIqEKLkTo83UpSiodShXmONwxdS3cvLrUryJU+plLH1SFMebOnSv7uLQrlX726quvyj49e/bMbXdFJFx6SXNzc267u34jRozIbW9oaJB9XKrPmjVrcttdAQf1TFHtEb5ojUr1cetBpTW5Pur5HqFT4NyzX60HNwZ3r/fr1y+3vW/fvrJPqfBNGACARNiEAQBIhE0YAIBE2IQBAEiETRgAgESSFXBQEXcuos1RUX8u8rB///657Z07d5Z9XBTo8uXLc9vXr18v+6jobRcd7SIwVYShi7pV0ZQuCtu9oF2dk4t+VBHp7iXxqjhBhI7IdetLjc9Forq1otakmwf3EvsiBg4cmNvu5k4VPXnllVdkHzevau25eVDR7cuWLZN93LVQ41u5cqXsM2zYsNz26upq2ef555+Xx9SzyK1xVVTE3c8u4rtI1kBlZWW7PivCR7FPmjQpt11FsEdEDB06NLfdFXhx9626z1TkdinxTRgAgETYhAEASIRNGACARNiEAQBIhE0YAIBE2IQBAEikpClKLnxcUSH5ET6Uf8uWLbntKt0iQqdJqZeFR0SsWLGi3WNQ7RE65cnNg0vtUMUBXAqCKozhUhBc2tWYMWNy213BBXXMFdMoUpTCpXao9ASX5uZSyYqs/71797a7T5HPc8U0VGqHShOJ8AU91Jp0qTSrVq3KbXfr2F0ndZ9VVFTIPuo54K65SueJiFi3bl1uu1vHKsXMPaPcGlJFLlxqjjonN9/uPlPFE9zcqbRHd67umHquuIIxpcI3YQAAEmETBgAgETZhAAASYRMGACARNmEAABJhEwYAIJGSpii5lBSVZlOkskqErppTJG2hsbGx3X0idBUX93mq8pJKZ4iIGDJkiDymQu9ViH+Erojk5ttVyFJVZtQ1cp+n0sgidGpVhF5H7pxUak7Rqlqqn0rRiPDVqYpQ8+euhUqtKlKVJiLi9NNPz21X1bsidEWdHTt2yD6uupi6Ti7lSaWruNSzAQMGyGNqjbsxNDQ0tOuzInz6oDrmzkk9x106j0pLc/3cGlLr1aW5OeredKlVpcI3YQAAEmETBgAgETZhAAASYRMGACARNmEAABIpaXR0r1692t3HRdy56DkVBe0iJtUxF6HtInLVy9Hdy+2XLVvWrs+K8C9bV1HQbtwTJ07MbVdRzhE+SrVIJGOHDvl/HnRRvC7SWUUFu4IQRbioUnXMFRVxGQVFqDly0fJqjlykepFCCNOmTZN96urqctt/9rOfyT5qDUXoCGRXCEEVAVEZDRH+vlCRzq4wjRq3G4PLrFBR5+6+UNfWXXM3BpUBMHjwYNlHcYVu3HpV94XbY0qFb8IAACTCJgwAQCJswgAAJMImDABAImzCAAAkwiYMAEAiJU1Rci98V2lARV4kHqFfaL537952j8FxKTMqZN+lTqg0rpdeeqnQGFSKlytkoebOpYu5NBv1Yn6XiqGOuevn0q7UnLu0JnXMrTuX2qE+z10Ll5pWhEq5cNdP3ReukIVLBXzuuedy212hAXUvqdSlCF9MQ/VzRSQWLlyY2+5SL90cqbXi5k7dF01NTbLPmjVr5DE1R25NqrQmlwLknh3q3nT3s1oP7v4rUryHAg4AABxH2IQBAEiETRgAgETYhAEASIRNGACAREoaHe2i3dSLt91LwYsUcHDRiurl6I6L3i4SHa0iDIcOHSr7uAhfNT4XOdrS0tLuPi5iWF0Ld/1UFKi7Ri5KXEX4uuIXW7ZsOaZjUFzU5rF+gbxaDy4iVxXacNGwLtpazau7Fioq3hUVcZGyVVVVue0bNmyQfdauXZvbrs4nQmcaROg17p6TqtiBK4bi7ls1BvdMUXOk5iciYtCgQfKYii5395laX+7Z6u4zdb5uHZcK34QBAEiETRgAgETYhAEASIRNGACARNiEAQBIhE0YAIBESpqi5MLeVWh5kXSeCB1aXqTYgUtrciHs6nxdOogag0obOtyx3r17y2OKOid3/VyKkrqGRdJ53AvVXQEOlZ7g1pdKY3EpJC4NosiadJ9XhEoDcukgas5d+qCbV7Umd+zYIfuoQhY1NTWyj6POafny5bLPunXrctvdufbp00ceU+fk7iXVp0jxkgidAuf6qLlzxUZcEQn1HHf3hUr9UqmuEX6Nq37u2V8qfBMGACARNmEAABJhEwYAIBE2YQAAEmETBgAgETZhAAASKWmKkqsootIdXDpPkQpLLuxdVZhxfVx6kAq9d6k0ao7cGFzqUJHqIOp3FQ3XV9fCVXdRaRCuj6NSLlRKmPtdbh5cNRuVbuTSS4qer6LO161JNXeuwlORFBc3D6qKkmqP8OkqanxTp06VfZYsWZLbvnLlStln69at8piqOjR48GDZR1U9cqlsLvVLXXf33K2srMxtVxWeInz6kjJgwAB5TD1b1fxE+PRGdU8Xqax3tPgmDABAImzCAAAkwiYMAEAibMIAACTCJgwAQCIljY5evXq1PDZq1KjcdlekwUVTqsjpbt26yT4qUtBFqLpjnTrlT6eLHFVRjioiMcJHaKsITDW2CB1F6IpBuAhtdQ1VNHpEsYIeRYodFHm5vYuOdhHDan25iE4XbV1E//79c9tdJLGKlnfn6qJhi6xxFaXqng/V1dXt/jyXNaDm7k9/+pPs88wzz8hjas6HDRsm+zQ3N+e2u2eAi/BV5+uyBtSzw10/t45VURH3fFf3oCt+UbS4w1uNb8IAACTCJgwAQCJswgAAJMImDABAImzCAAAkwiYMAEAiJU1RUqHoERFNTU257S71pVevXvKYCuV3KSlFXtjvXiCvQvldaocKsXch9Js2bZLHVFi+e5m5K7RxLBVJC3CpVS5FqciL74/1+FR6nEuLceu/CDU+lw6ixl1VVSX7uHtGzasrIqG469ezZ095TP0ul0a5YcOG3PZly5bJPs7IkSNz213hAvXMc88h9WyNiKipqcltd8Vx1LV1zxRXREI9k92aHDRoULvH4O5N9XxwKXClwjdhAAASYRMGACARNmEAABJhEwYAIBE2YQAAEilpdLSLTlORlu5F8I6KuHMvEldRhFu3bpV91EvdI3QEpovoVC/Ld/PgilKoaGtXjEG9+N5FKzoqGtYVLlBz5CJoXTRzkc9T1+JYc9HoLvK9CHUPunNVEaJuTbro2iKFUhRXBMS9zF/N+e9//3vZZ/78+bntbg3V1dXJY6rggTsnFQU9duxY2Wf9+vXyWJFiGkWunyrQE6GfyVu2bJF9VOS7e665Z796drh1XCp8EwYAIBE2YQAAEmETBgAgETZhAAASYRMGACARNmEAABIpaYqSK1ygQsSLvsBehfmrggYR+sXkruiDSydQY29paZF91Mvb6+vrZZ9169bJY+p83Tnt2bMnt929hN2F8qu0GJeqpcbnXlTv1or6PJeaU6TQgDsnNa8utcqtryLU57mUFNXHvdxeFVCJiKitrc1td/Oq1pBLO3GpOS+99FJu+6JFi2Qftb5cGtKxLhij5sFdCzXfEXq9unWnzsk9W12xDzXn7nmjimm4+8+NT92D7vqVCt+EAQBIhE0YAIBE2IQBAEiETRgAgETYhAEASIRNGACAREqaotSnTx95TIWjb9u2TfZxYfmqspALOVcpVC61yqUHqXQCF3qvKjm5cbsqPD169Mhtd+kgKg3IVaVxc6TmwVXh2bVrV7vGdjhqjty8FklbcJXCVNqHm7s1a9bIY0Wo9Bc3hiLVpFQlrgidRuLS3FTFLZfe5e4zNQ8jR46UfVRKkaroE+HXg0qvculdau7U/RJRbI27imlqrbjng0sfVGNwa6i8vDy33VVmc8fU+FxaU6nwTRgAgETYhAEASIRNGACARNiEAQBIhE0YAIBEShod7SJbVdSfi7jbvHmzPKYiDF20ooqgddGPLjpTnVPv3r3bPQY3dy76scgLyNWcuyhZ9+J0FeG+ZcsW2UdForoxuEhGFYnqXpavIjDdNXcR+yoi3fVxhRWKUL9LFZdwevXqJY+5F/ar9eCimdV9654P7j5T192NW60hF/nrCiEsW7Yst91dC5Xt4K6FG4P6XW5NFolUd5HJ/fv3b/cY1PPGXT83BvV5ar5LiW/CAAAkwiYMAEAibMIAACTCJgwAQCJswgAAJMImDABAIiVNUXIvJleh4O6l7i69RKUuuDSITZs25ba7tCb34ns1Plc8Qb043aUZuJetqxQEl3bl5qi9vydCp5IVScVw10KlNUXo83UpLm7tFRmDSj9z863SYopSaRpuHrZu3Zrb7sbm0nZU4Q6VEhah7yWXsuaOqXNyKSm1tbW57a4QibtvTznllNx2N69qHmpqamQfNw9qfG5NqjXkUoBcgQl1XxRZ+27cbn0pjY2N7e5ztPgmDABAImzCAAAkwiYMAEAibMIAACTCJgwAQCJlmQtxO/gHzcu6AQBAW0eyvfJNGACARNiEAQBIhE0YAIBE2IQBAEiETRgAgETYhAEASIRNGACARNiEAQBIhE0YAIBE2IQBAEiETRgAgETYhAEASIRNGACARDqV8sOvv/56eaxr16657fv375d93LHt27fntr/22muyT/fu3XPbV69eLfusX79eHlPjU2OLiOjbt29u++mnny77qLmLiOjZs2du+86dO2UfN6+K+zw1vtraWtmnoqIit71bt26yzwknnCCPKa+//ro8piqeuEoorrqYmqOmpibZZ8uWLbntn/3sZ2UfZ/r06bntb7zxhuyj1pC6Xw73eWoe3L25Z8+e3Pbq6mrZp0MH/Z1iw4YNue3Nzc2yj7q2u3fvln3U3EVEdO7cObfdrS/Vp1Mn/ejetWuXPKaeX67P5s2bc9vVNYrQ446IKC8vz213zzXVx3HP3X379uW2uzW0ZMmSdo/hSPBNGACARNiEAQBIhE0YAIBE2IQBAEiETRgAgERKGh3dpUuXdvdx0bAuIldF4+3du1f26dWrV267i350x0aOHJnb7iJHTzrppNz2gQMHyj4qWtH9LhddqPq46GMXTamiHHv37i37qPG5yFFHrQd3TmpeO3bsKPu49ar6uajNmpoaeawIFYHs1qSKenWRo06RSNQiEbR1dXXymLrX3bVQz6+iUeIqQtuNQa3jHTt2yD7umaeurXuuqUhst/ZPPPFEeUxlKLhoa3X9XHaCy4RQa9KdU6nwTRgAgETYhAEASIRNGACARNiEAQBIhE0YAIBE2IQBAEikpClKRdJLXBrS1q1b293PhfKrEHb3gn2XmqPSX0aMGCH7qFB5V0TCUakBLkVJpTS4wg79+vWTx1TqiXupu0rncWvIvcReXQuXbqSOud/jihAUWf8uBacIdS1coQE1d+5c1TqO0Gk7Lp1HpZ5s3LhR9nHnpAqEbNu2TfZRx9x94T5v8eLFue3ueaPSdorcS66fW+PqOvXo0aPdvycioqWlpd191HPcpVa5lCeVfubWeKnwTRgAgETYhAEASIRNGACARNiEAQBIhE0YAIBEShod7aLdVNSme6m7inCMiKisrMxtd9HRanzV1dWyj4u4U1F/7qXgKjK56Ava1Ty4a6EicotGBavoURdZrn6Xe0G7Ww9qDO6c3BwpLsJXRUeraxThz7cIFensorDVtXWZC+6F/Spy2kUSq89zY3j11VflMTWvmzZtkn3UfebmzhUNUOfropnVuF00uvs8tf7d2lf3kjtXVyhFjcH1UfuCe066KHa1xt3clQrfhAEASIRNGACARNiEAQBIhE0YAIBE2IQBAEiETRgAgERKmqLkXvCt0jdcioYLYVcv5O7Vq5fso9JLhg8f3u7f4z7PpVWokHg3d664g0qhcqlf6sX3Lm1h8+bN8phKn3ApSmoe3Ev5XZqGSp9wfYqkSbmUJ/W7XHrXsU5RUnPuXnyvroVLx3KpIm7OFVWsZfv27bKPK5jh0vqUPn365Lb3799f9nFFZtR1d+ek1kPR4gnqOrk+atyuiItbK+qYu37qfu7du7fs4+ZVPZPdfVEqfBMGACARNmEAABJhEwYAIBE2YQAAEmETBgAgETZhAAASKWmKkgsfVykDLkzdHSsvL89td6HyKp3HVbnp3r27PKZSMVy1EdXHpTU1NTXJYwMGDMhtr6qqkn1UdRdXMarIdXIpZioVw6VWqWseoVMNilSsKVpZRfVz6+FYa2xsbHcfNedFUkgidHUxl6qlbNmyRR5zKTPjxo3LbXdVlBYuXJjbvnHjRtnHpZip50qRdB6XuufGoFKRXMUhlYbn0nncvame/UXS89zz2N23qkqXm9fly5cf8bjag2/CAAAkwiYMAEAibMIAACTCJgwAQCJswgAAJFLS6Gj3UndVCMFF1bkoQsVFyKkoUBe12bVrV3lMRYgWiSJ0fdzL6NUcqWhAR0VNH46KwHQv8leFBtz1c8fU57n1pdaki9p0EcNqfbnPcxHpRajzddH36sX3btx1dXXymIrm37Bhg+xTU1OT2+4i7N19sXLlynZ/npo7F6Ht5lVFbxcpAuKehS7Ct8h6UM8BV8zGUfety6ZRc+SyJ1zBGHXd+/btK/uUCt+EAQBIhE0YAIBE2IQBAEiETRgAgETYhAEASIRNGACAREqaorR161Z5TKU7uJewu8IKKmTfhd5369Ytt929zNyluPTp0ye33c3DkiVL2j0Gl0KlXjI+aNAg2Ue9BL25uVn2celL6hq6dJ7Vq1fntrtUDJeeoNaXmzuVOuFSMdx1UmNX6y7i2KcoqbVXZF5dSphLs3GpQ4paK+6F/S4NT6WrnH766bLPwIEDc9uff/552Wf+/PnymFpHtbW1so86X5fO466tmiN1rhE6LdPdf5s3b5bHVAEMd05q3G5NuqI1aj0UTbs6GnwTBgAgETZhAAASYRMGACARNmEAABJhEwYAIJGSRkerggYREdXV1bntLgLaFU9Q0bDuZevqJd4u4s5FHqrCBS5qU41hwYIFso978b36XevWrZN9VMS3epF/hI+OVi/fd5Hq6kX1r7zyiuzjoox79eqV217k5fZOkUj6otH3Rbi1rKj71kWOuuIc6pi7n9V1cgUX3Lyq6G2XAaCeRW7cQ4cOlcdU1oCLiFfPtYqKCtnHPaNcdoCiopZ79Ogh+7jnuLo33bjV9XPrrr6+Xh4rUjCmVPgmDABAImzCAAAkwiYMAEAibMIAACTCJgwAQCJswgAAJFLSFCUXRq/C1F3aiQt7V1xBiPXr1+e2r1mzRvZpamqSx/785z/ntrvCBTt27MhtdylFqk+ETuFQhR0iiqWkuPQlNa8uRUnNuXsRvEsnUIULGhoaZB+VFuNSX4oea+8YilJjcKkq6j5z68GlrKmUnr59+8o+6tq6tEeXrqLuQVVAJSJi7dq1ue3uGeXmSN3TLkVJpayp1KUIn0KljrnUL/XMc9dcpWtG6NQm93lqHbsiEu5aqPVQpNjI0eKbMAAAibAJAwCQCJswAACJsAkDAJAImzAAAImwCQMAkEhJU5RcepBKQXBh5S41QKXMuDQRlYrhqhQ5qgqIq+SkwvJdqLyqUuR+l6tQotIgXMqASw3YtGlTbnv37t1lnz59+uS2uzQkd21VlS5X0Uqlv7hzdeNTaRAuvcSlihSh5tylKKl7sGj6hvo8dy1UeuPu3bvb3SdCX4vVq1fLPio1x1W6cveZOqbSNSP0c82lY7l5VdfCrWN1X7hr4cag0qTcPKi5c88Ady3U2F06aanwTRgAgETYhAEASIRNGACARNiEAQBIhE0YAIBEShodXSSy1UW7uSjjItGPLS0tue0qujfCRyWqSEYXpaciBV10oYtKVOfrzqmuri63vWikrrruLsp44MCBue1uPbhroX6XG4M61qmTvk1cpLMa+65du2QflwFQhJoj94J9FQ3rCoe4yHf1wn4Xba2i5adPny77uOt05513ymOKuk6qQEmEX18q+tcVQ6mqqsptd9HtjppzV0RCzasrFOHWiurXv39/2Udx67hIkRI3D6XCN2EAABJhEwYAIBE2YQAAEmETBgAgETZhAAASYRMGACCRkqYouWIMmzdvzm13L/F2KU8qNcCl+qi0HVfAwaXFLFq0KLfdpSCo1A6XhlSkMIZL9XnhhRdy2921eNvb3iaPqevuUgZU6oRKVYnQayhCp6zV1tbKPmru3LVwa1z1c6lfrjhAESpVpMjL8l0akpsHlZKyc+dO2UeNz6V3uZfvq3l1aTbqdxUt4ODSlxS1hty95ObIPUOVnj175ra783HFX1QapRubet6odLoIP0dFiquUCt+EAQBIhE0YAIBE2IQBAEiETRgAgETYhAEASKSk0dHqJdkRxV4s76LnVLSbi0RVEZjuRfBr166Vx1RUtXuZuYpadpF9bh5UdGZNTY3sM2DAgNx2F/3oIltVpKy7tqpwgYtEHTRokDymIkRPO+002ae5uTm33UVHu/Wl5shFYLq1V4RaKy6aWa1Jl2ngxq3uTZdpoKKW3X2xfPlyeUxdp/r6+nb3WbJkiezjIrRVIQt3LxWJjnb3uurnnlHqHty6davs4zIX1Dw0NTXJPup3ufvPjU/Na5EI9qPFN2EAABJhEwYAIBE2YQAAEmETBgAgETZhAAASYRMGACCRkqYoFXlRvUu/cekqqgCAU1FRkdveu3dv2celq6gUJZdOsGXLltx2dz6q8ERExJ49e3LbVRqS48a9Zs0aeay6ujq3ffjw4bJPVVXVkQ/s/6PONUKvPZcGoVKUXGpOkaIBro9ak0WpVB+XHqRe2O9elu8+T61XV5xDpXG54irr16+Xx1paWnLb3TpWKXWuSINL/VLX3T3z1Ly63+MKOLhCLu0dgyt+4dKu3PwpTz/9dG776NGjZR+1jiP0+nLPlFLhmzAAAImwCQMAkAibMAAAibAJAwCQCJswAACJsAkDAJBISVOUXDqPSgdxlXZcpZaVK1fmtrtqHioNyFXS6N69uzymxu7GraqXuHQQ93kq/F+laEREbNy4MbfdVftx1HWvq6uTfdS4XRqLS4tRqSerVq2SfVRqx9ixY2Ufl/qlUlLctT3W1By5NCl13V3aXJF7xqUcqvt5+/btso+jzsml7KjUtNraWtnHVVlrbGzMbXdVj1T6krs33XVSzw6X8qTmoV+/frKPSxdTaZkupVU9x13K4bBhw+QxlX7pnimlwjdhAAASYRMGACARNmEAABJhEwYAIBE2YQAAEilpdLSKgovQRRJc5O/WrVvlMRXh66IVe/TokdvuIgVdxLeKrHMvBVe/y0XpuehH9btcUQr1gn33gvb+/fvLYyri1BVCUJGybj248amCEOqaR+gIXxe96l4SX6SoSJEX7Dsq6ty9RF9FjhaNli9SRELd6+7eVJkGEXodDR48WPZpaGjIbXcZEs8884w89thjj+W2u2uusgN69eol+7jiCSra2hV9UFHL7tnqou9VFonro55r7tnqiqGo+XPPm1LhmzAAAImwCQMAkAibMAAAibAJAwCQCJswAACJsAkDAJBISeOxXdi7Sl9yL+xXqRMROuTchamrdAeVsnO4YyolZdu2be3u416I71JFVMqMezm6CsuvrKyUfdy8qpSU+vp62UdxaW4uRUmlZLmX76tUEZcW44oQqBScoulnRai1olJV3BjcuN1aUSkzLiVFrS+39l3xF5W+5O4zdd1d0Q6XhqfSoTZs2CD7qGIfLkXJUSk97hmlUrJcSphLBVRjr66uln3UXuL6uJRWlWrarVs32adU+CYMAEAibMIAACTCJgwAQCJswgAAJMImDABAIiWNjnaRniqyzr1Y3r3oXEXRuii95ubm3HYXVbd+/Xp5TEVOu6hSFSHqxu0iRFUEuYsCVfO6efNm2cdFgfbr1y+33b1YXo3bzYMrnjBw4MDcdhf9qCIwXdSte4G8imx1Uf4uUrYIFRXv7iW1Vlw0sytyoda/i2xVa9ytIVW0I0Kfr1sPqkiJi4hXRR8iIkaNGpXb3tjYKPusXr06t33NmjWyj8uEUBHfLlpeRRK7+8/dM2oMLuJb/S43brdWFPesLhW+CQMAkAibMAAAibAJAwCQCJswAACJsAkDAJAImzAAAImUNEXJhcqrsPempibZx6V2qHQQl0KiflfRFCXVz4W9q3QQlwbh0ipaWlpy210hBDVHLo3FFTVQ5+tSBlQBAJfq4K7T2rVrc9tdSoO6FirdKcIXHFEpei71y6XoFTF8+PB2j2H79u257a5ghrvPVOqQK6ahng/qfCIi6urq5DGV8tS3b1/ZRxUuUGOLKJYWo1L6IvQzz92bLjVUXVtV8CRC34MvvPCC7FPk2VGkOIcrPOGurfpdrihFqfBNGACARNiEAQBIhE0YAIBE2IQBAEiETRgAgETYhAEASKSkKUouNUeF0bsUEpe+oULvXaqPCntX1XQi/PgGDRqU275x40bZR3EVYQYMGCCPqTQbl0KiUslcpRZX3UilO7gqPCrdSFWmiohYuXKlPKbSSJYtWyb7qDS3cePGyT5jx46Vx0aMGJHb7tKuXBpQESrNxqUoqfXv1r67Z1SajVvH6l6vr6+XfVwVHpWSouYnQj+/XAUxl7qn1rh7rqnngEuFcmk2auwu7VEdU/dLhH92qPQl93xQKYwVFRWyj0tpVddWpXiWEt+EAQBIhE0YAIBE2IQBAEiETRgAgETYhAEASKSk0dHuReIqEs5Fu7loaxUJp6KmI3R0n4v0HDVqlDymIg9dtKKKlHUvVHeRyZ065V9SF4GpIkTHjBkj+7jPUxG+NTU1sk9jY2Nuu5u7wYMHy2OLFi3KbXfR8iqydcmSJbKPi6ZUEaIuorq6uloeK0JF5rtxqwh7V5DFvUi/Z8+eue3uXj/llFPa9VkR/l5XzyJV6CNCPx/UPRbhC3qotewik9XzwUVhu2PqueuKX6hxu2ehW19qrbjnrnrmueeQWscRei27NV4qfBMGACARNmEAABJhEwYAIBE2YQAAEmETBgAgETZhAAASKWmKkgvlVyHnLg1Jvfg7Qqc7uEIIixcvzm1vaGiQfQYOHCiPqTQIV8ChX79+ue0u/ca9dF7NkUsHUcdcoQFXWEGdr0svUUaOHCmPuZfEb9myJbd96NChso9Kd3Avy1+1apU8ptLmXBqLGndRqmiAu89UaodL+XDX9owzzshtd2l4qliES2Nx1DV0BTPUGFw61vLly+UxVYRg+PDhso/irp9L2ylSOEelKj799NOyj3tWqzl3BRyKpA65z1N7EylKAAAcR9iEAQBIhE0YAIBE2IQBAEiETRgAgERKGh3d3Nwsj6liByqiNCJi9+7d8ph6YbiL+lMv89+zZ4/s4162rqIf3RhUdLSLTO7fv788pqL+3LhVtLV7EfxJJ50kjy1dujS3/Q9/+IPsU1ZWltteX18v+6giDe7zXISvith3EZMbNmyQx9T6f+aZZ2QfV2CiCHWfuQh7FYHsXsqv1n6EjoZVY4vQxRjcmnRjUBkALoNDrRU3Bpc1oCKG3b2uiie4a+HGoLg1qbIdHnvsMdlHFb+I8Bkripoj91xzkfQqSrxo9P3R4JswAACJsAkDAJAImzAAAImwCQMAkAibMAAAibAJAwCQSElTlNzLzFVouQv/V2kLETrVQIX4R+iX7w8YMED2cUUD1Evs+/btK/uo9CWXJrVs2TJ5TL283RVwUPNa5EXwETo1Z/PmzbLPaaedltvu0rEaGxvlsXnz5uW2uxfLq5QZl6I0fvx4eUwVT1i9erXs41KHilDpJe4+U/eSKxrQ1NQkj6lrUV1dLfuccsopue2uGIq7z9Q6cuek0mzcNXL3mSoosHbtWtnnwQcfzG1396ZadxG6+IT7PHXfurkr8rxxKWaKS/9010kVSlm/fn27x3C0+CYMAEAibMIAACTCJgwAQCJswgAAJMImDABAImzCAAAkUtIUJRWSH6GrYriQc1cxQ4W9u/SSYcOG5bYPHz5c9nFh+aqyiUpditCpSC5lYPHixfKYSsFx1YPU73LpXa7yS69evXLbhwwZIvuoeVCpBBE+fUmlDu3cuVP26d27d267O1fVJ0KncY0YMUL2UffMHXfcIfs46n5yqVpqrbi0E1c1Z+XKlbntK1askH1UGpd7prj1oNIR3TyouXP3s/s8tVZUGlKEvgf79Okj+wwcOFAeUxWWXDqpqvTmntWuGp66p1UVswidWuXuZ0d9nmovJb4JAwCQCJswAACJsAkDAJAImzAAAImwCQMAkEhJo6Nd5Kh6Wb6L4nWRkepl8O7zVLSne7m9iwhUUcYuclT1cZGCrriDish156SiSosWE1Bz5K6f4l6oXlVVJY+NHj06t33dunWyj4rqdvPgIvZVZP7u3btlH1fkoghVjKG8vFz2KVIExBX0UL/L9VFrxT1T3NypoifuflZRxi7yVxUvccfcvKpiMm4NuXNSGRxdu3aVfdQz1D1b3fjUdXfPSXX93Dp241NZLm5NlgrfhAEASIRNGACARNiEAQBIhE0YAIBE2IQBAEiETRgAgERKmqLkXnSuuHSQ2tpaeUylg6hUKMeFyrsXhqvUIRdGr9ITVEGKCJ9upFINXCpNZWVlbrsrfqFSXyL0S+xd+ob6Xe5cXaqISl9yRSTUdSorK5N9XBqEWkduPbjrVIQa+65du9r9WSqFy/2eiIiamprcdlcYQ3Hrwa0vNa8uBW7NmjW57e76uXlQ6S/q/ovQzwH3e5qamtr9eS5NauPGjfKY4tKkVJqZK36hztetIfd8UM/qY33/HQm+CQMAkAibMAAAibAJAwCQCJswAACJsAkDAJBISaOj3Qv7VVSbi9Lr27evPKYi61wUoerjIu5cxLD6PFVcIiJi69atue3btm2TfVxEruJeqF4kitdFb6vPc5Hlanwuut0VuVDXwkV1q4hJt47ddVLryK0H9YL9otT5uvtCHXORxO6+UAUhXFSwivJ3a19FYbsx7NixQ/ZR69/9njFjxshjqt/atWtln/vuuy+3XZ1PRLEI7SKf5+5nd9+qYy4zRh1zmSwuOlodK1Jk5mjxTRgAgETYhAEASIRNGACARNiEAQBIhE0YAIBE2IQBAEikpClKLkRcpTS49CCXFqNSF1wai+rj0lhcCLtKPXEvJldh/i7E36UgqFB+l/qiwvzd79m3b588pl4g79Ig1HV3aVLu89Ra2bx5s+yjzsldC7dWVNqVm1c3viLUeihyb27atEn2cQUh1O9yL/lX10+lLkX44g7qd7mUSDV3qgBBhF8rar26lCdViESlGkX4a6GOuT7qOXnyySfLPq54j5ojtx5UKqAbt3tWDxo0KLd9y5Ytsk+p8E0YAIBE2IQBAEiETRgAgETYhAEASIRNGACARNiEAQBIpKQpSi41Rx1TlWwifAUV1c+lkKj0F5ViE+FTc1TqiQt7VyH2btwuPUGNwVX7USlKro9LeVLX1qWDqOvn0mJcNSKVXuLSg/r165fb7qr9uOpU6pzcOi5SIctRc+5SfdQcuYo1roqSOidXNUelarlnikthVPeMqmIWoZ8P7v7bsGGDPKZSkdwzT43BpXK6FKq6urrcdpcap36XSyly1alU2pWryqTG59ZQkVQyly5WKnwTBgAgETZhAAASYRMGACARNmEAABJhEwYAIJGSRke7SGL1cm0XceeiElUEq3vJv4pMdpF9LjpTRZW6eVAvnXfz4D5PRTS7qGBlzZo18piLWla/y0Uzq2hwF4Xt1kNDQ0Nue7du3WQfFV3rIlGbm5vlMRX16j7PReYXodaKi8hVUdAu2tTdF+oedC/YV9GrLgLaRW+rKGgX+a4ivotGaKuiBq7wRN++fXPb3TNgxIgR8pia88bGRtln3bp1ue0ukt89Q1evXt3uMah7xkVHu2eoWpOuIESp8E0YAIBE2IQBAEiETRgAgETYhAEASIRNGACARNiEAQBIpCxzeQIH/2CBFBcAAI5XR7K98k0YAIBE2IQBAEiETRgAgETYhAEASIRNGACARNiEAQBIhE0YAIBE2IQBAEiETRgAgETYhAEASIRNGACARNiEAQBIpNOR/uAR1nkAAABHiG/CAAAkwiYMAEAibMIAACTCJgwAQCJswgAAJMImDABAImzCAAAkwiYMAEAibMIAACTy/wBGP51YI5Om3wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Average Loss: 0.0292\n",
      "Epoch 7/10, Average Loss: 0.0288\n",
      "Epoch 8/10, Average Loss: 0.0288\n",
      "Epoch 9/10, Average Loss: 0.0281\n",
      "Epoch 10/10, Average Loss: 0.0283\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "diffusion = ForwardDiffusion(timesteps=1000, beta_start=1e-4, beta_end=0.02)\n",
    "\n",
    "# Attention is applied at resolutions 8 and 16 (for 32x32 images)\n",
    "unet = UNet(\n",
    "    in_channels=1, \n",
    "    model_channels=128, \n",
    "    context_dim=512, \n",
    "    attention_resolutions=[8, 16]  # Apply attention at 8x8 and 16x16 feature maps\n",
    ").to(device)\n",
    "\n",
    "# Calculate and print model parameters\n",
    "total_params = sum(p.numel() for p in unet.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "\n",
    "trainer = DiffusionTrainer2D(unet, diffusion, scheduler=None)\n",
    "n_epochs = 10\n",
    "\n",
    "use_ema = True\n",
    "\n",
    "if use_ema:\n",
    "    ema_model = ExponentialMovingAverage(unet, decay=0.999)\n",
    "\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for x0, label in dataloader:\n",
    "        x0 = x0.to(device)\n",
    "\n",
    "        # Get context embeddings from CLIP\n",
    "        with torch.no_grad():\n",
    "            text_inputs = torch.cat([clip.tokenize(f\"a photo of a {dataloader.dataset.cifar10.classes[l]}\") for l in label]).to(device)\n",
    "            context = clip_model.encode_text(text_inputs).float()\n",
    "\n",
    "        loss = trainer.train_step(x0, context)\n",
    "        epoch_loss += loss\n",
    "        num_batches += 1\n",
    "        \n",
    "        if use_ema:\n",
    "            ema_model.update()\n",
    "    \n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Sample and visualize\n",
    "    if (epoch + 1) % 5 == 0:  \n",
    "        if use_ema:\n",
    "            ema_model.apply_shadow()\n",
    "        \n",
    "        # Grab random labels and get their context embeddings\n",
    "        with torch.no_grad():\n",
    "            random_labels = random.choices(range(10), k=4)\n",
    "            text_inputs = torch.cat([clip.tokenize(f\"a photo of a {dataloader.dataset.cifar10.classes[l]}\") for l in random_labels]).to(device)\n",
    "            sample_context = clip_model.encode_text(text_inputs).float()\n",
    "\n",
    "            samples = trainer.sample(sample_context, shape=(4, 1, 32, 32), device=device)\n",
    "            samples = samples.clamp(0, 1).cpu()\n",
    "            grid = torchvision.utils.make_grid(samples, nrow=2)\n",
    "            \n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(grid.permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "            plt.title(f'Epoch {epoch+1} - Labels: {[dataloader.dataset.cifar10.classes[l] for l in random_labels]}')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "        if use_ema:\n",
    "            ema_model.restore()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0844f8",
   "metadata": {},
   "source": [
    "# Now that we have a 2D diffusion model, we need to make a wrapper around the model to generate layers of the same object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7513984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D diffusion model wrapper for generating layers of the same object\n",
    "\n",
    "# the layer context dim is the dimension of the input that describes the previous layer\n",
    "# the granularity is the number of layers to generate and also the resolution of the unet input and output, so if we do positional encoding of the layer index, it will be in range(0, granularity)\n",
    "class LayerXLayerDiffusionModel(nn.Module):\n",
    "    def __init__(self, base_model: UNet, layer_context_dim=64, granularity=128, layer_by_layer_convergence=True):\n",
    "        \"\"\"\n",
    "        Wrapper for the 2D diffusion model to generate layers of the same object.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.base_model = base_model  # This is the 2D diffusion model (UNet)\n",
    "        self.layer_context_dim = layer_context_dim  # Dimension of the layer context input\n",
    "        self.granularity = granularity  # (number of layers to generate and also the resolution of the unet input and output)\n",
    "        self.layer_by_layer_convergence = layer_by_layer_convergence  # Whether to run diffusion to convergence for each layer\n",
    "\n",
    "        if self.layer_by_layer_convergence:\n",
    "            # create the forward diffusion process for each layer\n",
    "            self.layer_diffusion = ForwardDiffusion(timesteps=1000, beta_start=1e-4, beta_end=0.02)\n",
    "            \n",
    "\n",
    "        # Additional transformer block to integrate previous layer information\n",
    "\n",
    "        # I want to give positional encoding to the layer context as well (what layer it currently is out of the granularity) this can change\n",
    "        self.layer_positional_encoding = SinusoidalPosEmb(layer_context_dim)\n",
    "\n",
    "        self.layer_transformer = TransformerBlock(\n",
    "            channels=base_model.model_channels, \n",
    "            context_dim=layer_context_dim,\n",
    "            num_heads=8\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t, l, context, prev_layer_features):\n",
    "        # x is the current layer input (noisy)\n",
    "        # t is the current timestep\n",
    "        # l is the current layer index (0 to granularity-1)\n",
    "        # context is the global context (e.g. CLIP embedding)\n",
    "        # prev_layer_features is the features from the previous layer (None if first layer) \n",
    "        # Integrate previous layer features using transformer\n",
    "        if prev_layer_features is not None:\n",
    "            prev_layer_features = self.layer_transformer(prev_layer_features, context)\n",
    "        \n",
    "        layer_context = prev_layer_features if prev_layer_features is not None else torch.zeros_like(x)\n",
    "        layer_context += self.layer_positional_encoding(l.float())\n",
    "\n",
    "        # run full diffusion on this layer until convergence\n",
    "        if self.layer_by_layer_convergence:\n",
    "            # run the diffusion process for this layer until convergence\n",
    "            # this means we need to run the diffusion process for this layer until the noise is very low\n",
    "            batch_size = x.size(0)\n",
    "            for step in reversed(range(self.layer_diffusion.timesteps)):\n",
    "                t_layer = torch.full((batch_size,), step, device=x.device, dtype=torch.float32)\n",
    "                predicted_noise = self.base_model(x, t_layer, context, layer_context)\n",
    "\n",
    "                alpha_t = self.layer_diffusion.alphas[step]\n",
    "                alpha_hat_t = self.layer_diffusion.alpha_hats[step]\n",
    "                beta_t = self.layer_diffusion.betas[step]\n",
    "\n",
    "                if step > 0:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "\n",
    "                base_out = (1 / torch.sqrt(alpha_t)) * (x - ((1 - alpha_t) / torch.sqrt(1 - alpha_hat_t)) * predicted_noise) + torch.sqrt(beta_t) * noise\n",
    "        \n",
    "        else:\n",
    "            # otherwise we run a single step of diffusion for this layer, and outside of the class, we run the full diffusion process for all layers at once\n",
    "            base_out = self.base_model(x, t, context, layer_context)\n",
    "\n",
    "        return base_out, layer_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29192336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the 3d voxel dataset (inside the folder_path_{granularity}, there are .npy files of shape (granularity, granularity, granularity) with values in [0, 1])\n",
    "# the user will make a voxel dataset object for each granularity they want to train on\n",
    "class VoxelDataset(Dataset):\n",
    "    def __init__(self, npy_folder_path, description_folder_path, transform=None, granularity=128):\n",
    "        self.npy_folder_path = npy_folder_path\n",
    "        self.description_folder_path = description_folder_path\n",
    "        self.transform = transform\n",
    "        self.granularity = granularity\n",
    "       \n",
    "        self.file_list = list(Path(npy_folder_path).glob(\"*.npy\"))\n",
    "        assert len(self.file_list) > 0, f\"No .npy files found in {npy_folder_path}\"\n",
    "\n",
    "        self.descriptions = {}\n",
    "        for desc_file in Path(description_folder_path).glob(\"*.txt\"):\n",
    "            key = desc_file.stem  # filename without extension\n",
    "            with open(desc_file, 'r') as f:\n",
    "                self.descriptions[key] = f.read().strip()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        voxel_grid = np.load(self.file_list[idx]).astype(np.float32)  # shape (granularity, granularity, granularity)\n",
    "        assert voxel_grid.shape == (self.granularity, self.granularity, self.granularity), f\"Voxel grid shape {voxel_grid.shape} does not match expected shape {(self.granularity, self.granularity, self.granularity)}\"\n",
    "        \n",
    "        if self.transform:\n",
    "            voxel_grid = self.transform(voxel_grid)\n",
    "        \n",
    "        voxel_grid = torch.from_numpy(voxel_grid).unsqueeze(0)  # Add channel dimension -> shape (1, granularity, granularity, granularity)\n",
    "\n",
    "        filename_key = self.file_list[idx].stem\n",
    "        description = self.descriptions.get(filename_key, \"A 3D object\")  # Default description if not found\n",
    "        return voxel_grid, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4fa566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 3d difussion trainer for the layer x layer model\n",
    "\n",
    "class LayerXLayerDiffusionTrainer:\n",
    "    def __init__(self, model: LayerXLayerDiffusionModel, diffusion: ForwardDiffusion, scheduler, layer_by_layer_convergence=True):\n",
    "        self.model = model  # this is the layer x layer diffusion model\n",
    "        self.diffusion = diffusion  # this is the forward diffusion process (noise addition)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "        self.scheduler = scheduler  # can be None its the learning rate scheduler\n",
    "        self.layer_by_layer_convergence = layer_by_layer_convergence\n",
    "\n",
    "    def train_step(self, x0, context):\n",
    "        \"\"\"\n",
    "        x0: [B, C, H, W] the full object with all layers\n",
    "        context: [B, context_dim] the global context (e.g. CLIP embedding)\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        batch_size = x0.size(0)\n",
    "        device = x0.device\n",
    "\n",
    "        # Initialize previous layer features to None\n",
    "        prev_layer_features = None\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        # Iterate over each layer\n",
    "        for layer_idx in range(self.model.granularity):\n",
    "            # Extract the current layer from x0\n",
    "            current_layer = x0[:, :, :, layer_idx]  # [B, C, H, W-layer_idx]\n",
    "\n",
    "            # Randomly sample a timestep for this layer\n",
    "            t = torch.randint(0, self.diffusion.timesteps, (batch_size,), device=device).long()\n",
    "\n",
    "            # Add noise to the current layer\n",
    "            xt, noise = self.diffusion.forward(current_layer, t)\n",
    "\n",
    "            # Create a tensor for the current layer index\n",
    "            l = torch.full((batch_size,), layer_idx, device=device, dtype=torch.float32)\n",
    "\n",
    "            # Predict noise using the model\n",
    "            predicted_noise, prev_layer_features = self.model(xt, t.float(), l, context, prev_layer_features)\n",
    "\n",
    "            # Compute loss for this layer\n",
    "            loss = F.mse_loss(predicted_noise, noise)\n",
    "            total_loss += loss\n",
    "\n",
    "        # Backpropagate and optimize\n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.scheduler is not None:\n",
    "            self.scheduler.step()\n",
    "\n",
    "        avg_loss = total_loss.item() / self.model.granularity\n",
    "        return avg_loss\n",
    "\n",
    "\n",
    "    def layer_convergence_sample(self, context, shape, device):\n",
    "        \"\"\"\n",
    "        context: [B, context_dim] the global context (e.g. CLIP embedding)\n",
    "        shape: (B, C, H, W) the shape of each layer to generate\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_size = shape[0]\n",
    "            prev_layer_features = None\n",
    "\n",
    "            # Initialize an empty voxel grid\n",
    "            voxel_grid = torch.zeros((batch_size, shape[1], shape[2], self.model.granularity), device=device)\n",
    "\n",
    "            for layer_idx in range(self.model.granularity):\n",
    "                # Create a tensor for the current layer index\n",
    "                l = torch.full((batch_size,), layer_idx, device=device, dtype=torch.float32)\n",
    "\n",
    "                # Start with pure noise for this layer\n",
    "                x = torch.randn(shape, device=device)\n",
    "\n",
    "                # Run diffusion to convergence for this layer\n",
    "                for t in reversed(range(self.diffusion.timesteps)):\n",
    "                    t_batch = torch.full((batch_size,), t, device=device, dtype=torch.float32)\n",
    "                    predicted_noise, prev_layer_features = self.model(x, t_batch, l, context, prev_layer_features)\n",
    "\n",
    "                    alpha_t = self.diffusion.alphas[t]\n",
    "                    alpha_hat_t = self.diffusion.alpha_hats[t]\n",
    "                    beta_t = self.diffusion.betas[t]\n",
    "\n",
    "                    if t > 0:\n",
    "                        noise = torch.randn_like(x)\n",
    "                    else:\n",
    "                        noise = torch.zeros_like(x)\n",
    "\n",
    "                    x = (1 / torch.sqrt(alpha_t)) * (x - ((1 - alpha_t) / torch.sqrt(1 - alpha_hat_t)) * predicted_noise) + torch.sqrt(beta_t) * noise\n",
    "\n",
    "                # Place the generated layer into the voxel grid\n",
    "                voxel_grid[:, :, :, layer_idx] = x.squeeze(1)  # Remove channel dimension\n",
    "\n",
    "            return voxel_grid.clamp(0, 1)  # Return the full voxel grid\n",
    "        \n",
    "    def object_convergence_sample(self, context, shape, device):\n",
    "        \"\"\"\n",
    "        context: [B, context_dim] the global context (e.g. CLIP embedding)\n",
    "        shape: (B, C, H, W) the shape of each layer to generate\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_size = shape[0]\n",
    "            device = context.device\n",
    "\n",
    "            # Initialize an empty voxel grid\n",
    "            voxel_grid = torch.zeros((batch_size, shape[1], shape[2], self.model.granularity), device=device)\n",
    "\n",
    "            # Start with pure noise for the entire object\n",
    "            x = torch.randn((batch_size, shape[1], shape[2], self.model.granularity), device=device)\n",
    "\n",
    "            # Randomly sample a timestep for the entire object\n",
    "            t = torch.randint(0, self.diffusion.timesteps, (batch_size,), device=device).long()\n",
    "\n",
    "            # Initialize previous layer features to None\n",
    "            prev_layer_features = None\n",
    "\n",
    "            for layer_idx in range(self.model.granularity):\n",
    "                # Create a tensor for the current layer index\n",
    "                l = torch.full((batch_size,), layer_idx, device=device, dtype=torch.float32)\n",
    "\n",
    "                # Extract the current layer from x\n",
    "                current_layer = x[:, :, :, layer_idx]  # [B, C, H, W-layer_idx]\n",
    "\n",
    "                # Predict noise using the model\n",
    "                predicted_noise, prev_layer_features = self.model(current_layer, t.float(), l, context, prev_layer_features)\n",
    "\n",
    "                alpha_t = self.diffusion.alphas[t]\n",
    "                alpha_hat_t = self.diffusion.alpha_hats[t]\n",
    "                beta_t = self.diffusion.betas[t]\n",
    "\n",
    "                if layer_idx < self.model.granularity - 1:\n",
    "                    noise = torch.randn_like(current_layer)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(current_layer)\n",
    "\n",
    "                # Update the current layer in x\n",
    "                x[:, :, :, layer_idx] = (1 / torch.sqrt(alpha_t)) * (current_layer - ((1 - alpha_t) / torch.sqrt(1 - alpha_hat_t)) * predicted_noise) + torch.sqrt(beta_t) * noise\n",
    "\n",
    "                # Place the updated layer into the voxel grid\n",
    "                voxel_grid[:, :, :, layer_idx] = x[:, :, :, layer_idx]\n",
    "\n",
    "            return voxel_grid.clamp(0, 1)  # Return the full voxel grid\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e87c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the layer x layer diffusion model\n",
    "\n",
    "granularity = 32  # number of layers to generate and also the resolution of the unet input and output\n",
    "layer_context_dim = 64  # dimension of the layer context input\n",
    "layer_by_layer_convergence = True  # Whether to run diffusion to convergence for each layer\n",
    "layer_diffusion = ForwardDiffusion(timesteps=1000, beta_start=1e-4, beta_end=0.02)\n",
    "\n",
    "layer_x_layer_model = LayerXLayerDiffusionModel(\n",
    "    base_model=unet,\n",
    "    layer_context_dim=layer_context_dim,\n",
    "    granularity=granularity,\n",
    "    layer_by_layer_convergence=layer_by_layer_convergence\n",
    ").to(device)\n",
    "\n",
    "scheduler = None\n",
    "\n",
    "layer_x_layer_trainer = LayerXLayerDiffusionTrainer(\n",
    "    model=layer_x_layer_model,\n",
    "    diffusion=layer_diffusion,\n",
    "    scheduler=scheduler,\n",
    "    layer_by_layer_convergence=layer_by_layer_convergence\n",
    ")\n",
    "\n",
    "import clip\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "clip_model.eval()\n",
    "dataloader_3d = DataLoader(VoxelDataset(\n",
    "    npy_folder_path=f'./data/voxels_{granularity}', \n",
    "    description_folder_path='./data/descriptions', \n",
    "    granularity=granularity\n",
    "), batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "n_epochs_3d = 10\n",
    "use_ema_3d = True\n",
    "if use_ema_3d:\n",
    "    ema_model_3d = ExponentialMovingAverage(layer_x_layer_model, decay=0.999)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs_3d):\n",
    "    epoch_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for x0, description in dataloader_3d:\n",
    "        x0 = x0.to(device)  # [B, 1, H, W, D]\n",
    "\n",
    "        # Get context embeddings from CLIP\n",
    "        with torch.no_grad():\n",
    "            text_inputs = torch.cat([clip.tokenize(desc) for desc in description]).to(device)\n",
    "            context = clip_model.encode_text(text_inputs).float()\n",
    "\n",
    "        loss = layer_x_layer_trainer.train_step(x0, context)\n",
    "        epoch_loss += loss\n",
    "        num_batches += 1\n",
    "        \n",
    "        if use_ema_3d:\n",
    "            ema_model_3d.update()\n",
    "    \n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    print(f\"3D Epoch {epoch+1}/{n_epochs_3d}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Sample and visualize\n",
    "    if (epoch + 1) % 5 == 0:  \n",
    "        if use_ema_3d:\n",
    "            ema_model_3d.apply_shadow()\n",
    "        \n",
    "        # Grab random descriptions and get their context embeddings\n",
    "        with torch.no_grad():\n",
    "            random_descriptions = random.choices(list(dataloader_3d.dataset.descriptions.values()), k=2)\n",
    "            text_inputs = torch.cat([clip.tokenize(desc) for desc in random_descriptions]).to(device)\n",
    "            sample_context = clip_model.encode_text(text_inputs).float()\n",
    "\n",
    "            samples = layer_x_layer_trainer.layer_convergence_sample(\n",
    "                sample_context, \n",
    "                shape=(2, 1, granularity, granularity), \n",
    "                device=device\n",
    "            )  # [B, 1, H, W, D]\n",
    "            samples = samples.clamp(0, 1).cpu()\n",
    "\n",
    "            # Visualize the middle slice of the voxel grid for each sample\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "            for i in range(2):\n",
    "                mid_slice = samples[i, 0, :, :, granularity // 2]  # Middle slice along depth\n",
    "                axes[i].imshow(mid_slice, cmap='gray')\n",
    "                axes[i].set_title(f'Sample {i+1}\\n\"{random_descriptions[i][:30]}...\"')\n",
    "                axes[i].axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "        if use_ema_3d:\n",
    "            ema_model_3d.restore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
